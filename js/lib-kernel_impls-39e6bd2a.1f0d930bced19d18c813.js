/*! For license information please see lib-kernel_impls-39e6bd2a.1f0d930bced19d18c813.js.LICENSE.txt */
(self.webpackChunkfractalize=self.webpackChunkfractalize||[]).push([[260],{2069:(e,t,n)=>{"use strict";n.d(t,{$:()=>ge,A:()=>aa,B:()=>V,C:()=>U,D:()=>Y,E:()=>J,F:()=>Z,G:()=>X,H:()=>ee,I:()=>te,J:()=>ne,K:()=>re,L:()=>ae,M:()=>ca,N:()=>H,O:()=>ra,P:()=>se,Q:()=>oe,R:()=>la,S:()=>ua,T:()=>ie,U:()=>ue,V:()=>le,W:()=>ce,X:()=>he,Y:()=>pe,Z:()=>fe,_:()=>be,a:()=>sa,a$:()=>zt,a0:()=>we,a1:()=>ke,a2:()=>xe,a3:()=>ve,a4:()=>ye,a5:()=>Ee,a6:()=>I,a7:()=>Se,a8:()=>Me,a9:()=>Qe,aA:()=>ht,aB:()=>pt,aC:()=>mt,aD:()=>u,aE:()=>it,aF:()=>ft,aG:()=>bt,aH:()=>gt,aI:()=>wt,aJ:()=>kt,aK:()=>vt,aL:()=>yt,aM:()=>Et,aN:()=>$t,aO:()=>_t,aP:()=>St,aQ:()=>Mt,aR:()=>Qt,aS:()=>at,aT:()=>It,aU:()=>c,aV:()=>xt,aW:()=>At,aX:()=>Tt,aY:()=>Ct,aZ:()=>Dt,a_:()=>Kt,aa:()=>$e,ab:()=>Ie,ac:()=>Ae,ad:()=>Te,ae:()=>Ce,af:()=>Ke,ag:()=>ze,ah:()=>Re,ai:()=>Q,aj:()=>We,ak:()=>qe,al:()=>Ge,am:()=>Fe,an:()=>Pe,ao:()=>Be,ap:()=>Oe,aq:()=>Ve,ar:()=>He,as:()=>Le,at:()=>je,au:()=>Ue,av:()=>Ye,aw:()=>ot,ax:()=>ct,ay:()=>lt,az:()=>dt,b:()=>oa,b$:()=>l,b0:()=>Rt,b1:()=>qt,b2:()=>Gt,b3:()=>Ft,b4:()=>Pt,b5:()=>nn,b6:()=>rn,b7:()=>an,b8:()=>sn,b9:()=>on,bA:()=>In,bB:()=>Tn,bC:()=>Nt,bD:()=>Cn,bE:()=>Dn,bF:()=>Kn,bG:()=>zn,bH:()=>ut,bI:()=>Rn,bJ:()=>j,bK:()=>Wn,bL:()=>qn,bM:()=>p,bN:()=>Gn,bO:()=>Fn,bP:()=>Pn,bQ:()=>De,bR:()=>Bn,bS:()=>On,bT:()=>Vn,bU:()=>Hn,bV:()=>Ln,bW:()=>jn,bX:()=>_e,bY:()=>Un,bZ:()=>Ne,b_:()=>Yn,ba:()=>un,bb:()=>cn,bc:()=>ln,bd:()=>dn,be:()=>hn,bf:()=>pn,bg:()=>mn,bh:()=>fn,bi:()=>bn,bj:()=>gn,bk:()=>wn,bl:()=>kn,bm:()=>xn,bn:()=>vn,bo:()=>L,bp:()=>yn,bq:()=>En,br:()=>$n,bs:()=>_n,bt:()=>Nn,bu:()=>st,bv:()=>Wt,bw:()=>Sn,bx:()=>Mn,by:()=>Qn,bz:()=>An,c:()=>ia,c0:()=>Zn,c1:()=>Xn,c2:()=>er,c3:()=>tr,c4:()=>nr,c5:()=>rr,c6:()=>ar,c7:()=>sr,c8:()=>or,c9:()=>Zr,ca:()=>Xr,cb:()=>ea,cc:()=>Yr,cd:()=>pr,ce:()=>Jr,cf:()=>ta,cg:()=>na,ch:()=>ha,ci:()=>S,cj:()=>w,ck:()=>i,cl:()=>h,cm:()=>y,cn:()=>N,co:()=>fa,cp:()=>dr,cq:()=>ur,cr:()=>hr,cs:()=>g,ct:()=>b,d:()=>Cr,e:()=>nt,f:()=>Ze,g:()=>Je,h:()=>et,i:()=>tt,j:()=>A,k:()=>T,l:()=>C,m:()=>M,n:()=>ma,o:()=>D,p:()=>K,q:()=>z,r:()=>R,s:()=>W,t:()=>q,u:()=>G,v:()=>Xe,w:()=>F,x:()=>P,y:()=>B,z:()=>O}),n(3807),n(6282);var r=n(8075),a=n(3006);class s{constructor(e){this.modelArtifacts=e}async load(){return this.modelArtifacts}}class o{constructor(e){this.saveHandler=e}async save(e){return this.saveHandler(e)}}var i=Object.freeze({__proto__:null,browserFiles:r.cX,browserHTTPRequest:r.cT,concatenateArrayBuffers:r.cY,decodeWeights:r.cV,encodeWeights:r.cZ,fromMemory:function(e,t,n,r){return 1===arguments.length?null!=e.modelTopology||null!=e.weightSpecs?new s(e):(console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."),new s({modelTopology:e})):(console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."),new s({modelTopology:e,weightSpecs:t,weightData:n,trainingConfig:r}))},getLoadHandlers:r.cU,getModelArtifactsInfoForJSON:r.c_,getSaveHandlers:r.cW,http:r.c$,isHTTPScheme:r.d0,loadWeights:r.d1,registerLoadRouter:r.d2,registerSaveRouter:r.d3,weightsLoaderFactory:r.d4,withSaveHandler:function(e){return new o(e)},copyModel:r.d5,listModels:r.d6,moveModel:r.d7,removeModel:r.d8});const u=(0,r.w)({matMul_:function(e,t,n=!1,a=!1){let s=(0,r.d9)(e,"a","matMul"),o=(0,r.d9)(t,"b","matMul");[s,o]=(0,r.da)(s,o);const i={a:s,b:o},u={transposeA:n,transposeB:a};return r.db.runKernel(r.ao,i,u)}}),c=(0,r.w)({oneHot_:function(e,t,n=1,a=0){if(t<2)throw new Error(`Error in oneHot: depth must be >=2, but it is ${t}`);const s={indices:(0,r.d9)(e,"indices","oneHot","int32")},o={depth:t,onValue:n,offValue:a};return r.db.runKernel(r.bK,s,o)}}),l=(0,r.w)({transpose_:function(e,t){const n=(0,r.d9)(e,"x","transpose");if(null==t&&(t=n.shape.map(((e,t)=>t)).reverse()),(0,r.cQ)(n.rank===t.length,(()=>`Error in transpose: rank of input ${n.rank} must match length of perm ${t}.`)),t.forEach((e=>{(0,r.cQ)(e>=0&&e<n.rank,(()=>"All entries in 'perm' must be between 0 and "+(n.rank-1)+` but got ${t}`))})),n.rank<=1)return n.clone();const a={x:n},s={perm:t};return r.db.runKernel(r.cx,a,s)}}),d=(0,r.w)({confusionMatrix_:function(e,t,n){const a=(0,r.d9)(e,"labels","confusionMatrix"),s=(0,r.d9)(t,"predictions","confusionMatrix");(0,r.cQ)(null==n||n>0&&Number.isInteger(n),(()=>`If provided, numClasses must be a positive integer, but got ${n}`)),(0,r.cQ)(1===a.rank,(()=>`Expected the rank of labels to be 1, but got ${a.rank}`)),(0,r.cQ)(1===s.rank,(()=>`Expected the rank of predictions to be 1, but got ${s.rank}`)),(0,r.cQ)(a.shape[0]===s.shape[0],(()=>`Mismatch in the number of examples: ${a.shape[0]} vs. ${s.shape[0]}. Labels and predictions should have the same number of elements.`)),(0,r.cQ)(n>0&&Number.isInteger(n),(()=>`numClasses is required to be a positive integer, but got ${n}`));const o=c((0,r.d)(a,"int32"),n),i=c((0,r.d)(s,"int32"),n),d=l(o),h=u(d,i);return(0,r.d)(h,"int32")}});var h=Object.freeze({__proto__:null,confusionMatrix:d});function p(e,t,n){if((0,r.dc)(e),null!=t&&3!==t.length)throw new Error("tensor3d() requires shape to have three numbers");const a=(0,r.dd)(e,n);if(3!==a.length&&1!==a.length)throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");if(1===a.length&&null==t)throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");return(0,r.de)(e,t,a,n)}let m;function f(e,t=3){if(t>4)throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");if(null==e)throw new Error("pixels passed to tf.browser.fromPixels() can not be null");let n=!1,a=!1,s=!1,o=!1,i=!1,u=!1;if(e.data instanceof Uint8Array)n=!0;else if("undefined"!=typeof ImageData&&e instanceof ImageData)a=!0;else if("undefined"!=typeof HTMLVideoElement&&e instanceof HTMLVideoElement)s=!0;else if("undefined"!=typeof HTMLImageElement&&e instanceof HTMLImageElement)o=!0;else if(null!=e.getContext)i=!0;else{if(!("undefined"!=typeof ImageBitmap&&e instanceof ImageBitmap))throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${e.constructor.name}`);u=!0}if(s){const t=2;if(s&&e.readyState<t)throw new Error("The video element has not loaded data yet. Please wait for `loadeddata` event on the <video> element.")}if(null!=(0,r._)(r.cD,r.db.backendName)){const n={pixels:e},a={numChannels:t};return r.db.runKernel(r.cD,n,a)}const[c,l]=s?[e.videoWidth,e.videoHeight]:[e.width,e.height];let d,h;if(i?d=e.getContext("2d").getImageData(0,0,c,l).data:a||n?d=e.data:(o||s||u)&&(null==m&&(m=document.createElement("canvas").getContext("2d")),m.canvas.width=c,m.canvas.height=l,m.drawImage(e,0,0,c,l),d=m.getImageData(0,0,c,l).data),4===t)h=new Int32Array(d);else{const e=c*l;h=new Int32Array(e*t);for(let n=0;n<e;n++)for(let e=0;e<t;++e)h[n*t+e]=d[4*n+e]}return p(h,[l,c,t],"int32")}async function b(e,t){let n=(0,r.d9)(e,"img","toPixels");if(!(e instanceof r.T)){const e=n;n=(0,r.d)(e,"int32"),e.dispose()}if(2!==n.rank&&3!==n.rank)throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${n.rank}.`);const[a,s]=n.shape.slice(0,2),o=2===n.rank?1:n.shape[2];if(o>4||2===o)throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${o}`);if("float32"!==n.dtype&&"int32"!==n.dtype)throw new Error(`Unsupported type for toPixels: ${n.dtype}. Please use float32 or int32 tensors.`);const i=await n.data(),u="float32"===n.dtype?255:1,c=new Uint8ClampedArray(s*a*4);for(let e=0;e<a*s;++e){const t=[0,0,0,255];for(let r=0;r<o;r++){const a=i[e*o+r];if("float32"===n.dtype){if(a<0||a>1)throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${a}.`)}else if("int32"===n.dtype&&(a<0||a>255))throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${a}.`);1===o?(t[0]=a*u,t[1]=a*u,t[2]=a*u):t[r]=a*u}const r=4*e;c[r+0]=Math.round(t[0]),c[r+1]=Math.round(t[1]),c[r+2]=Math.round(t[2]),c[r+3]=Math.round(t[3])}if(null!=t){t.width=s,t.height=a;const e=t.getContext("2d"),n=new ImageData(c,s,a);e.putImageData(n,0,0)}return n!==e&&n.dispose(),c}const g=(0,r.w)({fromPixels_:f});var w=Object.freeze({__proto__:null,fromPixelsAsync:async function(e,t=3){let n=null;if((0,r.e)().getBool("WRAP_TO_IMAGEBITMAP")&&function(e){return"undefined"!=typeof window&&"undefined"!=typeof ImageBitmap&&window.hasOwnProperty("createImageBitmap")&&!(e instanceof ImageBitmap)&&function(e){return null!=e&&0!==e.width&&0!==e.height}(e)&&!function(e){return null!=e&&e.data instanceof Uint8Array}(e)}(e)){let t;try{t=await createImageBitmap(e,{premultiplyAlpha:"none"})}catch(e){t=null}n=null!=t&&t.width===e.width&&t.height===e.height?t:e}else n=e;return f(n,t)},toPixels:b,fromPixels:g});class k{getClassName(){return this.constructor.className}static fromConfig(e,t){return new e(t)}}class x{constructor(){this.classNameMap={}}static getMap(){return null==x.instance&&(x.instance=new x),x.instance}static register(e){x.getMap().classNameMap[e.className]=[e,e.fromConfig]}}function v(e){(0,r.cQ)(null!=e.className,(()=>"Class being registered does not have the static className property defined.")),(0,r.cQ)("string"==typeof e.className,(()=>"className is required to be a string, but got type "+typeof e.className)),(0,r.cQ)(e.className.length>0,(()=>"Class being registered has an empty-string as its className, which is disallowed.")),x.register(e)}var y=Object.freeze({__proto__:null,Serializable:k,SerializationMap:x,registerClass:v});function E(){return 32===r.db.backend.floatPrecision()?.001:.1}function $(e,t,n){let a=!0;if(((0,r.df)(e)||(0,r.df)(t))&&(a=!1),(0,r.df)(e)&&(0,r.df)(t)&&(a=!0),a){const n=e.constructor.name,r=t.constructor.name;if(n!==r)throw new Error(`Arrays are of different type. Actual: ${n}. Expected: ${r}`)}if(Array.isArray(e)&&Array.isArray(t)){const n=(0,r.dd)(e),a=(0,r.dd)(t);if(!(0,r.cR)(n,a))throw new Error(`Arrays have different shapes. Actual: [${n}]. Expected: [${a}]`)}const s=(0,r.df)(e)?e:(0,r.dg)(e),o=(0,r.df)(t)?t:(0,r.dg)(t);if(s.length!==o.length)throw new Error(`Arrays have different lengths actual: ${s.length} vs expected: ${o.length}.\nActual:   ${s}.\nExpected: ${o}.`);for(let e=0;e<o.length;++e){const t=s[e],r=o[e];if(!n(t,r))throw new Error(`Arrays differ: actual[${e}] = ${t}, expected[${e}] = ${r}.\nActual:   ${s}.\nExpected: ${o}.`)}}function _(e,t,n){return!isFinite(e)&&!isFinite(t)||!(isNaN(e)||isNaN(t)||Math.abs(e-t)>n)}var N=Object.freeze({__proto__:null,TEST_EPSILON_FLOAT16:.1,expectArraysClose:function(e,t,n){return null==n&&(n=E()),$(e,t,((e,t)=>_(e,t,n)))},testEpsilon:E,expectPromiseToFail:function(e,t){e().then((()=>t.fail()),(()=>t()))},expectArraysEqual:function(e,t){const n="string"==typeof t||"number"==typeof t||"boolean"==typeof t?[t]:t;return(0,r.dh)(e)||(0,r.dh)(e[0])||(0,r.dh)(t)||(0,r.dh)(t[0])?$(e,n,((e,t)=>e==t)):$(e,t,((e,t)=>_(e,t,0)))},expectNumbersClose:function(e,t,n){if(null==n&&(n=E()),!_(e,t,n))throw new Error(`Numbers differ: actual === ${e}, expected === ${t}`)},expectValuesInRange:function(e,t,n){for(let r=0;r<e.length;r++)if(e[r]<t||e[r]>n)throw new Error(`Value out of range:${e[r]} low: ${t}, high: ${n}`)},expectArrayBuffersEqual:function(e,t){expect(new Float32Array(e)).toEqual(new Float32Array(t))},encodeStrings:function e(t){for(let n=0;n<t.length;n++){const a=t[n];Array.isArray(a)?e(a):t[n]=(0,r.di)(a)}return t}});const S="3.7.0",M=(0,r.w)({add_:function(e,t){let n=(0,r.d9)(e,"a","add"),a=(0,r.d9)(t,"b","add");[n,a]=(0,r.da)(n,a);const s={a:n,b:a};return r.db.runKernel(r.a9,s)}}),Q=(0,r.w)({floorDiv_:function(e,t){let n=(0,r.d9)(e,"a","floorDiv"),a=(0,r.d9)(t,"b","floorDiv");[n,a]=(0,r.da)(n,a);const s={a:n,b:a};return r.db.runKernel(r.b2,s)}}),I=(0,r.w)({div_:function(e,t){let n=(0,r.d9)(e,"a","div"),a=(0,r.d9)(t,"b","div");if([n,a]=(0,r.da)(n,a),"int32"===n.dtype&&"int32"===a.dtype)return Q(n,a);const s={a:n,b:a};return r.db.runKernel(r.aR,s,{})}}),A=(0,r.w)({abs_:function(e){const t=(0,r.d9)(e,"x","abs");if("complex64"===t.dtype){const e={x:t};return r.db.runKernel(r.aw,e)}{const e={x:t};return r.db.runKernel(r.a6,e)}}}),T=(0,r.w)({acos_:function(e){const t={x:(0,r.d9)(e,"x","acos")};return r.db.runKernel(r.a7,t)}}),C=(0,r.w)({acosh_:function(e){const t={x:(0,r.d9)(e,"x","acosh")};return r.db.runKernel(r.a8,t)}}),D=(0,r.w)({addN_:function(e){(0,r.cQ)(Array.isArray(e),(()=>"The argument passed to tf.addN() must be a list of tensors")),(0,r.cQ)(e.length>=1,(()=>`Must pass at least one tensor to tf.addN(), but got ${e.length}`));const t=e.map(((e,t)=>(0,r.d9)(e,`tensors${t}`,"addN"))),n=t[0];t.forEach((e=>{if(e.dtype!==n.dtype)throw new Error("All tensors passed to tf.addN() must have the same dtype")})),t.forEach((e=>{if(!(0,r.cR)(e.shape,n.shape))throw new Error("All tensors passed to tf.addN() must have the same shape")}));const a=t;return r.db.runKernel(r.aa,a)}}),K=(0,r.w)({all_:function(e,t=null,n=!1){const a={x:(0,r.d9)(e,"x","all","bool")},s={axis:t,keepDims:n};return r.db.runKernel(r.ab,a,s)}}),z=(0,r.w)({any_:function(e,t=null,n=!1){const a={x:(0,r.d9)(e,"x","any","bool")},s={axis:t,keepDims:n};return r.db.runKernel(r.ac,a,s)}}),R=(0,r.w)({argMax_:function(e,t=0){const n={x:(0,r.d9)(e,"x","argMax")},a={axis:t};return r.db.runKernel(r.ad,n,a)}}),W=(0,r.w)({argMin_:function(e,t=0){const n={x:(0,r.d9)(e,"x","argMin")},a={axis:t};return r.db.runKernel(r.ae,n,a)}}),q=(0,r.w)({asin_:function(e){const t={x:(0,r.d9)(e,"x","asin")};return r.db.runKernel(r.af,t)}}),G=(0,r.w)({asinh_:function(e){const t={x:(0,r.d9)(e,"x","asinh")};return r.db.runKernel(r.ag,t)}}),F=(0,r.w)({atan_:function(e){const t={x:(0,r.d9)(e,"x","atan")};return r.db.runKernel(r.ah,t)}}),P=(0,r.w)({atan2_:function(e,t){let n=(0,r.d9)(e,"a","atan2"),a=(0,r.d9)(t,"b","atan2");[n,a]=(0,r.da)(n,a);const s={a:n,b:a};return r.db.runKernel(r.aj,s)}}),B=(0,r.w)({atanh_:function(e){const t={x:(0,r.d9)(e,"x","atanh")};return r.db.runKernel(r.ai,t)}}),O=(0,r.w)({avgPool_:function(e,t,n,a,s){const o=(0,r.d9)(e,"x","avgPool","float32");(0,r.cQ)((0,r.dj)(n,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`));let i=o,u=!1;3===o.rank&&(u=!0,i=(0,r.k)(o,[1,o.shape[0],o.shape[1],o.shape[2]])),(0,r.cQ)(4===i.rank,(()=>`Error in avgPool: x must be rank 4 but got rank ${i.rank}.`)),null!=s&&(0,r.cQ)((0,r.dk)(a),(()=>`Error in avgPool: pad must be an integer when using, dimRoundingMode ${s} but got pad ${a}.`));const c={x:i},l={filterSize:t,strides:n,pad:a,dimRoundingMode:s};let d=r.db.runKernel(r.ak,c,l);return d=(0,r.d)(d,o.dtype),u?(0,r.k)(d,[d.shape[1],d.shape[2],d.shape[3]]):d}}),V=(0,r.w)({avgPool3d_:function(e,t,n,a,s,o="NDHWC"){const i=(0,r.d9)(e,"x","avgPool3d","float32");let u=i,c=!1;4===i.rank&&(c=!0,u=(0,r.k)(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),(0,r.cQ)(5===u.rank,(()=>`Error in avgPool3d: x must be rank 5 but got rank ${u.rank}.`)),(0,r.cQ)("NDHWC"===o,(()=>`Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${o}`)),null!=s&&(0,r.cQ)((0,r.dk)(a),(()=>`Error in avgPool3d: pad must be an integer when using, dimRoundingMode ${s} but got pad ${a}.`));const l={x:u},d={filterSize:t,strides:n,pad:a,dimRoundingMode:s,dataFormat:o};let h=r.db.runKernel(r.am,l,d);return h=(0,r.d)(h,u.dtype),c?(0,r.k)(h,[h.shape[1],h.shape[2],h.shape[3],h.shape[4]]):h}}),H=(0,r.w)({concat_:function(e,t=0){(0,r.cQ)(e.length>=1,(()=>"Pass at least one tensor to concat"));const n=(0,r.dl)(e,"tensors","concat","string_or_numeric");if("complex64"===n[0].dtype&&n.forEach((e=>{if("complex64"!==e.dtype)throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${e.dtype}. `)})),1===n.length)return(0,r.f)(n[0]);const a=n,s={axis:t};return r.db.runKernel(r.ax,a,s)}}),L=(0,r.w)({slice_:function(e,t,n){const a=(0,r.d9)(e,"x","slice","string_or_numeric");if(0===a.rank)throw new Error("Slicing scalar is not possible");const s={x:a},o={begin:t,size:n};return r.db.runKernel(r.c5,s,o)}}),j=(0,r.w)({tanh_:function(e){const t={x:(0,r.d9)(e,"x","tanh")};return r.db.runKernel(r.ct,t)}}),U=(0,r.w)({basicLSTMCell_:function(e,t,n,a,s,o){const i=(0,r.d9)(e,"forgetBias","basicLSTMCell"),c=(0,r.d9)(t,"lstmKernel","basicLSTMCell"),l=(0,r.d9)(n,"lstmBias","basicLSTMCell"),d=(0,r.d9)(a,"data","basicLSTMCell"),h=(0,r.d9)(s,"c","basicLSTMCell"),p=(0,r.d9)(o,"h","basicLSTMCell"),m=H([d,p],1),f=u(m,c),b=M(f,l),g=b.shape[0],w=b.shape[1]/4,k=[g,w],x=L(b,[0,0],k),v=L(b,[0,w],k),y=L(b,[0,2*w],k),E=L(b,[0,3*w],k),$=M((0,r.m)((0,r.o)(x),j(v)),(0,r.m)(h,(0,r.o)(M(i,y))));return[$,(0,r.m)(j($),(0,r.o)(E))]}}),Y=(0,r.w)({batchToSpaceND_:function(e,t,n){const a=(0,r.d9)(e,"x","batchToSpaceND"),s=t.reduce(((e,t)=>e*t));(0,r.cQ)(a.rank>=1+t.length,(()=>`input rank is ${a.rank} but should be > than blockShape.length ${t.length}`)),(0,r.cQ)(n.length===t.length,(()=>`crops.length is ${n.length} but should be equal to blockShape.length  ${t.length}`)),(0,r.cQ)(a.shape[0]%s==0,(()=>`input tensor batch is ${a.shape[0]} but is not divisible by the product of the elements of blockShape ${t.join(" * ")} === ${s}`));const o={x:a},i={blockShape:t,crops:n};return r.db.runKernel(r.ap,o,i)}}),J=(0,r.w)({batchNorm_:function(e,t,n,a,s,o){null==o&&(o=.001);const i=(0,r.d9)(e,"x","batchNorm"),u=(0,r.d9)(t,"mean","batchNorm"),c=(0,r.d9)(n,"variance","batchNorm");let l,d;null!=s&&(l=(0,r.d9)(s,"scale","batchNorm")),null!=a&&(d=(0,r.d9)(a,"offset","batchNorm")),(0,r.cQ)(u.rank===c.rank,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),(0,r.cQ)(null==d||u.rank===d.rank,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),(0,r.cQ)(null==l||u.rank===l.rank,(()=>"Batch normalization gradient requires mean and scale to have equal ranks."));const h={x:function(e){let t;return t=0===e.rank||1===e.rank?(0,r.k)(e,[1,1,1,e.size]):2===e.rank?(0,r.k)(e,[1,1,e.shape[0],e.shape[1]]):3===e.rank?(0,r.k)(e,[1,e.shape[0],e.shape[1],e.shape[2]]):e,t}(i),scale:l,offset:d,mean:u,variance:c},p={varianceEpsilon:o},m=r.db.runKernel(r.b3,h,p);return(0,r.k)(m,i.shape)}}),Z=(0,r.w)({batchNorm2d_:function(e,t,n,a,s,o){const i=(0,r.d9)(e,"x","batchNorm"),u=(0,r.d9)(t,"mean","batchNorm"),c=(0,r.d9)(n,"variance","batchNorm");let l,d;return null!=s&&(l=(0,r.d9)(s,"scale","batchNorm")),null!=a&&(d=(0,r.d9)(a,"offset","batchNorm")),(0,r.cQ)(2===i.rank,(()=>`Error in batchNorm2D: x must be rank 2 but got rank ${i.rank}.`)),(0,r.cQ)(2===u.rank||1===u.rank,(()=>`Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${u.rank}.`)),(0,r.cQ)(2===c.rank||1===c.rank,(()=>`Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${c.rank}.`)),null!=l&&(0,r.cQ)(2===l.rank||1===l.rank,(()=>`Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${l.rank}.`)),null!=d&&(0,r.cQ)(2===d.rank||1===d.rank,(()=>`Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${d.rank}.`)),J(i,u,c,d,l,o)}}),X=(0,r.w)({batchNorm3d_:function(e,t,n,a,s,o){const i=(0,r.d9)(e,"x","batchNorm"),u=(0,r.d9)(t,"mean","batchNorm"),c=(0,r.d9)(n,"variance","batchNorm");let l,d;return null!=s&&(l=(0,r.d9)(s,"scale","batchNorm")),null!=a&&(d=(0,r.d9)(a,"offset","batchNorm")),(0,r.cQ)(3===i.rank,(()=>`Error in batchNorm3D: x must be rank 3 but got rank ${i.rank}.`)),(0,r.cQ)(3===u.rank||1===u.rank,(()=>`Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${u.rank}.`)),(0,r.cQ)(3===c.rank||1===c.rank,(()=>`Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${c.rank}.`)),null!=l&&(0,r.cQ)(3===l.rank||1===l.rank,(()=>`Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${l.rank}.`)),null!=d&&(0,r.cQ)(3===d.rank||1===d.rank,(()=>`Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${d.rank}.`)),J(i,u,c,d,l,o)}}),ee=(0,r.w)({batchNorm4d_:function(e,t,n,a,s,o){const i=(0,r.d9)(e,"x","batchNorm"),u=(0,r.d9)(t,"mean","batchNorm"),c=(0,r.d9)(n,"variance","batchNorm");let l,d;return null!=s&&(l=(0,r.d9)(s,"scale","batchNorm")),null!=a&&(d=(0,r.d9)(a,"offset","batchNorm")),(0,r.cQ)(4===i.rank,(()=>`Error in batchNorm4D: x must be rank 4 but got rank ${i.rank}.`)),(0,r.cQ)(4===u.rank||1===u.rank,(()=>`Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${u.rank}.`)),(0,r.cQ)(4===c.rank||1===c.rank,(()=>`Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${c.rank}.`)),null!=l&&(0,r.cQ)(4===l.rank||1===l.rank,(()=>`Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${l.rank}.`)),null!=d&&(0,r.cQ)(4===d.rank||1===d.rank,(()=>`Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${d.rank}.`)),J(i,u,c,d,l,o)}}),te=(0,r.w)({bincount_:function(e,t,n){const a=(0,r.d9)(e,"x","bincount"),s=(0,r.d9)(t,"weights","bincount");(0,r.cQ)("int32"===a.dtype,(()=>`Error in bincount: input dtype must be int32, but got ${a.dtype}`)),(0,r.cQ)(n>=0,(()=>`size must be non-negative, but got ${n}.`)),(0,r.cQ)(s.size===a.size||0===s.size,(()=>`Error in bincount: weights must have the same size as input or0-length, but got input shape: ${a.shape}, weights shape: ${s.shape}.`));const o={x:a,weights:s},i={size:n};return r.db.runKernel(r.aq,o,i)}}),ne=(0,r.w)({broadcastTo_:function(e,t){let n=(0,r.d9)(e,"broadcastTo","x");const a=n.shape;if(t.some((e=>!(e>0)||e%1!=0)))throw new Error(`broadcastTo(): Invalid broadcast shape [${t}].`);if(t.length<n.rank)throw new Error(`broadcastTo(): shape.length=${t.length} < input.rank=${n.rank}.`);if(t.length>n.rank){const e=n.shape.slice();for(;e.length<t.length;)e.unshift(1);n=(0,r.k)(n,e)}const s=n.shape,o=Array.from(t);for(let e=t.length-1;e>=0;e--)if(s[e]===t[e])o[e]=1;else if(1!==n.shape[e])throw new Error(`broadcastTo(): [${a}] cannot be broadcast to [${t}].`);if(0===o.map(((e,t)=>e>1?t:-1)).filter((e=>e>=0)).length)return(0,r.f)(n);const i={x:n},u={reps:o};return r.db.runKernel(r.cu,i,u)}}),re=(0,r.w)({ceil_:function(e){const t={x:(0,r.d9)(e,"x","ceil")};return r.db.runKernel(r.at,t)}}),ae=(0,r.w)({clipByValue_:function(e,t,n){const a=(0,r.d9)(e,"x","clipByValue");(0,r.cQ)(t<=n,(()=>`Error in clip: min (${t}) must be less than or equal to max (${n}).`));const s={x:a},o={clipValueMin:t,clipValueMax:n};return r.db.runKernel(r.au,s,o)}}),se=(0,r.w)({concat1d_:function(e){return H(e,0)}}),oe=(0,r.w)({concat2d_:function(e,t){return H(e,t)}}),ie=(0,r.w)({concat3d_:function(e,t){return H(e,t)}}),ue=(0,r.w)({concat4d_:function(e,t){return H(e,t)}}),ce=(0,r.w)({conv2d_:function(e,t,n,a,s="NHWC",o=[1,1],i){const u=(0,r.d9)(e,"x","conv2d"),c=(0,r.d9)(t,"filter","conv2d");let l=u,d=!1;3===u.rank&&(d=!0,l=(0,r.k)(u,[1,u.shape[0],u.shape[1],u.shape[2]])),(0,r.cQ)(4===l.rank,(()=>`Error in conv2d: input must be rank 4, but got rank ${l.rank}.`)),(0,r.cQ)(4===c.rank,(()=>`Error in conv2d: filter must be rank 4, but got rank ${c.rank}.`)),null!=i&&(0,r.cQ)((0,r.dk)(a),(()=>`Error in conv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`));const h="NHWC"===s?l.shape[3]:l.shape[1];(0,r.cQ)(h===c.shape[2],(()=>`Error in conv2d: depth of input (${h}) must match input depth for filter ${c.shape[2]}.`)),(0,r.cQ)((0,r.dj)(n,o),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${o}'`));const p={x:l,filter:c},m={strides:n,pad:a,dataFormat:s,dilations:o,dimRoundingMode:i},f=r.db.runKernel(r.ay,p,m);return d?(0,r.k)(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),le=(0,r.w)({conv1d_:function(e,t,n,a,s="NWC",o=1,i){const u=(0,r.d9)(e,"x","conv1d"),c=(0,r.d9)(t,"filter","conv1d");let l=u,d=!1;2===u.rank&&(d=!0,l=(0,r.k)(u,[1,u.shape[0],u.shape[1]])),(0,r.cQ)(3===l.rank,(()=>`Error in conv1d: input must be rank 3, but got rank ${l.rank}.`)),(0,r.cQ)(3===c.rank,(()=>`Error in conv1d: filter must be rank 3, but got rank ${c.rank}.`)),null!=i&&(0,r.cQ)((0,r.dk)(a),(()=>`Error in conv1d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`)),(0,r.cQ)(l.shape[2]===c.shape[1],(()=>`Error in conv1d: depth of input (${l.shape[2]}) must match input depth for filter ${c.shape[1]}.`)),(0,r.cQ)((0,r.dj)(n,o),(()=>`Error in conv1D: Either stride or dilation must be 1. Got stride ${n} and dilation '${o}'`)),(0,r.cQ)("NWC"===s,(()=>`Error in conv1d: got dataFormat of ${s} but only NWC is currently supported.`));const h=(0,r.k)(c,[1,c.shape[0],c.shape[1],c.shape[2]]),p=(0,r.k)(l,[l.shape[0],1,l.shape[1],l.shape[2]]),m=ce(p,h,[1,n],a,"NHWC",[1,o],i);return d?(0,r.k)(m,[m.shape[2],m.shape[3]]):(0,r.k)(m,[m.shape[0],m.shape[2],m.shape[3]])}}),de=(0,r.w)({conv2DBackpropInput_:function(e,t,n,a,s,o="NHWC",i){(0,r.cQ)(e.length===t.rank,(()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`));let u=e,c=t,l=!1;3===t.rank&&(l=!0,c=(0,r.k)(t,[1,t.shape[0],t.shape[1],t.shape[2]]),u=[1,e[0],e[1],e[2]]),(0,r.cQ)(4===u.length,(()=>`Error in conv2dDerInput: inShape must be length 4, but got length ${u.length}.`)),(0,r.cQ)(4===c.rank,(()=>`Error in conv2dDerInput: dy must be rank 4, but got rank ${c.rank}`)),(0,r.cQ)(4===n.rank,(()=>`Error in conv2dDerInput: filter must be rank 4, but got rank ${n.rank}`));const d="NHWC"===o?u[3]:u[1],h="NHWC"===o?c.shape[3]:c.shape[1];(0,r.cQ)(d===n.shape[2],(()=>`Error in conv2dDerInput: depth of input (${d}) must match input depth for filter ${n.shape[2]}.`)),(0,r.cQ)(h===n.shape[3],(()=>`Error in conv2dDerInput: depth of output (${h}) must match output depth for filter ${n.shape[3]}.`)),null!=i&&(0,r.cQ)((0,r.dk)(s),(()=>`Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode ${i} but got pad ${s}.`));const p={dy:c,filter:n},m={strides:a,pad:s,dataFormat:o,dimRoundingMode:i,inputShape:u},f=r.db.runKernel(r.aA,p,m);return l?(0,r.k)(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),he=(0,r.w)({conv2dTranspose_:function(e,t,n,a,s,o){const i=(0,r.d9)(e,"x","conv2dTranspose"),u=(0,r.d9)(t,"filter","conv2dTranspose");return de(n,i,u,a,s,"NHWC",o)}}),pe=(0,r.w)({conv3d_:function(e,t,n,a,s="NDHWC",o=[1,1,1]){const i=(0,r.d9)(e,"x","conv3d"),u=(0,r.d9)(t,"filter","conv3d");let c=i,l=!1;4===i.rank&&(l=!0,c=(0,r.k)(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),(0,r.cQ)(5===c.rank,(()=>`Error in conv3d: input must be rank 5, but got rank ${c.rank}.`)),(0,r.cQ)(5===u.rank,(()=>`Error in conv3d: filter must be rank 5, but got rank ${u.rank}.`)),(0,r.cQ)(c.shape[4]===u.shape[3],(()=>`Error in conv3d: depth of input (${c.shape[4]}) must match input depth for filter ${u.shape[3]}.`)),(0,r.cQ)((0,r.dj)(n,o),(()=>`Error in conv3D: Either strides or dilations must be 1. Got strides ${n} and dilations '${o}'`)),(0,r.cQ)("NDHWC"===s,(()=>`Error in conv3d: got dataFormat of ${s} but only NDHWC is currently supported.`));const d={x:c,filter:u},h={strides:n,pad:a,dataFormat:s,dilations:o},p=r.db.runKernel(r.aB,d,h);return l?(0,r.k)(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),me=(0,r.w)({conv3DBackpropInput_:function(e,t,n,a,s){(0,r.cQ)(e.length===t.rank,(()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`));let o=e,i=t,u=!1;4===t.rank&&(u=!0,i=(0,r.k)(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]]),o=[1,e[0],e[1],e[2],e[3]]);const c=o[4],l=i.shape[4];(0,r.cQ)(5===o.length,(()=>`Error in conv3dDerInput: inShape must be length 5, but got length ${o.length}.`)),(0,r.cQ)(5===i.rank,(()=>`Error in conv3dDerInput: dy must be rank 5, but got rank ${i.rank}`)),(0,r.cQ)(5===n.rank,(()=>`Error in conv3dDerInput: filter must be rank 5, but got rank ${n.rank}`)),(0,r.cQ)(c===n.shape[3],(()=>`Error in conv3dDerInput: depth of input (${c}) must match input depth for filter ${n.shape[3]}.`)),(0,r.cQ)(l===n.shape[4],(()=>`Error in conv3dDerInput: depth of output (${l}) must match output depth for filter ${n.shape[4]}.`));const d={dy:i,filter:n},h={pad:s,strides:a,inputShape:o},p=r.db.runKernel(r.aD,d,h);return u?(0,r.k)(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),fe=(0,r.w)({conv3dTranspose_:function(e,t,n,a,s){const o=(0,r.d9)(e,"x","conv3dTranspose"),i=(0,r.d9)(t,"filter","conv3dTranspose");return me(n,o,i,a,s)}}),be=(0,r.w)({cos_:function(e){const t={x:(0,r.d9)(e,"x","cos")};return r.db.runKernel(r.aE,t)}}),ge=(0,r.w)({cosh_:function(e){const t={x:(0,r.d9)(e,"x","cosh")};return r.db.runKernel(r.aF,t)}}),we=(0,r.w)({cumsum_:function(e,t=0,n=!1,a=!1){const s={x:(0,r.d9)(e,"x","cumsum")},o={axis:t,exclusive:n,reverse:a};return r.db.runKernel(r.aG,s,o)}}),ke=(0,r.w)({denseBincount_:function(e,t,n,a=!1){const s=(0,r.d9)(e,"x","denseBincount"),o=(0,r.d9)(t,"weights","denseBincount");(0,r.cQ)("int32"===s.dtype,(()=>`Error in denseBincount: input dtype must be int32, but got ${s.dtype}`)),(0,r.cQ)(s.rank<=2,(()=>`Error in denseBincount: input must be at most rank 2, but got rank ${s.rank}.`)),(0,r.cQ)(n>=0,(()=>`size must be non-negative, but got ${n}.`)),(0,r.cQ)(o.size===s.size||0===o.size,(()=>`Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${s.shape}, weights shape: ${o.shape}.`));const i={x:s,weights:o},u={size:n,binaryOutput:a};return r.db.runKernel(r.aI,i,u)}}),xe=(0,r.w)({depthToSpace_:function(e,t,n="NHWC"){const a=(0,r.d9)(e,"x","depthToSpace"),s="NHWC"===n?a.shape[1]:a.shape[2],o="NHWC"===n?a.shape[2]:a.shape[3],i="NHWC"===n?a.shape[3]:a.shape[1];(0,r.cQ)(s*t>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${s} and ${t}  for depthToSpace with input shape\n    ${a.shape}`)),(0,r.cQ)(o*t>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${o} and ${t} for depthToSpace with input shape\n        ${a.shape}`)),(0,r.cQ)(i%(t*t)==0,(()=>`Dimension size must be evenly divisible by ${t*t} but is ${i} for depthToSpace with input shape ${a.shape}`));const u={x:a},c={blockSize:t,dataFormat:n};return r.db.runKernel(r.aJ,u,c)}}),ve=(0,r.w)({depthwiseConv2d_:function(e,t,n,a,s="NHWC",o=[1,1],i){const u=(0,r.d9)(e,"x","depthwiseConv2d"),c=(0,r.d9)(t,"filter","depthwiseConv2d");let l=u,d=!1;3===u.rank&&(d=!0,l=(0,r.k)(u,[1,u.shape[0],u.shape[1],u.shape[2]])),(0,r.cQ)(4===l.rank,(()=>`Error in depthwiseConv2d: input must be rank 4, but got rank ${l.rank}.`)),(0,r.cQ)(4===c.rank,(()=>`Error in depthwiseConv2d: filter must be rank 4, but got rank ${c.rank}.`)),(0,r.cQ)(l.shape[3]===c.shape[2],(()=>`Error in depthwiseConv2d: number of input channels (${l.shape[3]}) must match the inChannels dimension in filter ${c.shape[2]}.`)),null!=i&&(0,r.cQ)((0,r.dk)(a),(()=>`Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`));const h={x:l,filter:c},p={strides:n,pad:a,dataFormat:s,dilations:o,dimRoundingMode:i},m=r.db.runKernel(r.aK,h,p);return d?(0,r.k)(m,[m.shape[1],m.shape[2],m.shape[3]]):m}}),ye=(0,r.w)({diag_:function(e){const t={x:(0,r.d9)(e,"x","diag")};return r.db.runKernel(r.aN,t)}}),Ee=(0,r.w)({dilation2d_:function(e,t,n,a,s=[1,1],o="NHWC"){const i=(0,r.d9)(e,"x","dilation2d"),u=(0,r.d9)(t,"filter","dilation2d");(0,r.cQ)(3===i.rank||4===i.rank,(()=>`Error in dilation2d: input must be rank 3 or 4, but got rank ${i.rank}.`)),(0,r.cQ)(3===u.rank,(()=>`Error in dilation2d: filter must be rank 3, but got rank ${u.rank}.`)),(0,r.cQ)("NHWC"===o,(()=>`Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${o}`));let c=i,l=!1;3===i.rank&&(c=(0,r.k)(i,[1,i.shape[0],i.shape[1],i.shape[2]]),l=!0);const d={x:c,filter:u},h={strides:n,pad:a,dilations:s},p=r.db.runKernel(r.aO,d,h);return l?(0,r.k)(p,[p.shape[1],p.shape[2],p.shape[3]]):p}}),$e=(0,r.w)({equal_:function(e,t){let n=(0,r.d9)(e,"a","equal","string_or_numeric"),a=(0,r.d9)(t,"b","equal","string_or_numeric");[n,a]=(0,r.da)(n,a),(0,r.dm)(n.shape,a.shape);const s={a:n,b:a};return r.db.runKernel(r.aW,s)}}),_e=(0,r.w)({where_:function(e,t,n){const a=(0,r.d9)(t,"a","where"),s=(0,r.d9)(n,"b","where"),o=(0,r.d9)(e,"condition","where","bool"),i=(0,r.dm)((0,r.dm)(o.shape,a.shape),s.shape),u={condition:ne(o,i),t:ne(a,i),e:ne(s,i)};return r.db.runKernel(r.c3,u)}}),Ne=(0,r.w)({zerosLike_:function(e){const t={x:(0,r.d9)(e,"x","zerosLike")};return r.db.runKernel(r.cB,t)}}),Se=(0,r.w)({divNoNan_:function(e,t){let n=(0,r.d9)(e,"a","div"),a=(0,r.d9)(t,"b","div");[n,a]=(0,r.da)(n,a);const s=I(n,a),o=Ne(s),i=$e(a,o);return _e(i,o,s)}}),Me=(0,r.w)({dot_:function(e,t){const n=(0,r.d9)(e,"t1","dot"),a=(0,r.d9)(t,"t2","dot");(0,r.cQ)(!(1!==n.rank&&2!==n.rank||1!==a.rank&&2!==a.rank),(()=>`Error in dot: inputs must all be rank 1 or 2, but got ranks ${n.rank} and ${a.rank}.`));const s=1===n.rank?n.size:n.shape[1],o=1===a.rank?a.size:a.shape[0];if((0,r.cQ)(s===o,(()=>`Error in dot: inner dimensions of inputs must match, but got ${s} and ${o}.`)),1===n.rank&&1===a.rank){const e=(0,r.k)(n,[1,-1]),t=(0,r.k)(a,[-1,1]),s=u(e,t);return(0,r.k)(s,[])}if(1===n.rank&&2===a.rank){const e=(0,r.k)(n,[1,-1]),t=(0,r.k)(a,[a.shape[0],a.shape[1]]),s=u(e,t);return(0,r.k)(s,[s.size])}if(2===n.rank&&1===a.rank){const e=(0,r.k)(a,[-1,1]),t=u(n,e);return(0,r.k)(t,[t.size])}{const e=(0,r.k)(a,[a.shape[0],a.shape[1]]);return u(n,e)}}}),Qe=(0,r.w)({einsum_:function(e,...t){const n=t.map(((e,t)=>(0,r.d9)(e,`tensors${t}`,"einsum"))),a={equation:e};return r.db.runKernel(r.aS,n,a)}}),Ie=(0,r.w)({erf_:function(e){let t=(0,r.d9)(e,"x","erf");(0,r.cQ)("int32"===t.dtype||"float32"===t.dtype,(()=>"Input dtype must be `int32` or `float32`.")),"int32"===t.dtype&&(t=(0,r.d)(t,"float32"));const n={x:t};return r.db.runKernel(r.aV,n)}}),Ae=(0,r.w)({exp_:function(e){const t={x:(0,r.d9)(e,"x","exp")};return r.db.runKernel(r.aX,t)}}),Te=(0,r.w)({expandDims_:function(e,t=0){const n=(0,r.d9)(e,"x","expandDims","string_or_numeric");(0,r.cQ)(t<=n.rank,(()=>"Axis must be <= rank of the tensor"));const a={input:n},s={dim:t};return r.db.runKernel(r.aY,a,s)}}),Ce=(0,r.w)({expm1_:function(e){const t={x:(0,r.d9)(e,"x","expm1")};return r.db.runKernel(r.aZ,t)}}),De=(0,r.w)({tile_:function(e,t){const n=(0,r.d9)(e,"x","tile","string_or_numeric");(0,r.cQ)(n.rank===t.length,(()=>`Error in transpose: rank of input ${n.rank} must match length of reps ${t}.`));const a={x:n},s={reps:t};return r.db.runKernel(r.cu,a,s)}}),Ke=(0,r.w)({eye_:function(e,t,n,a="float32"){null==t&&(t=e);const s=(0,r.c)([e,t],a),o=e<=t?e:t;for(let e=0;e<o;++e)s.set(1,e,e);const i=(0,r.k)(s.toTensor(),[e,t]);if(null==n)return i;if(1===n.length)return De(Te(i,0),[n[0],1,1]);if(2===n.length)return De(Te(Te(i,0),0),[n[0],n[1],1,1]);if(3===n.length)return De(Te(Te(Te(i,0),0),0),[n[0],n[1],n[2],1,1]);throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${n.length}D.`)}});function ze(e,t,n){const a={shape:e,value:t,dtype:n};return r.db.runKernel(r.a$,{},a)}const Re=(0,r.w)({floor_:function(e){const t={x:(0,r.d9)(e,"x","floor")};return r.db.runKernel(r.b1,t)}}),We=(0,r.w)({gather_:function(e,t,n=0,a=0){const s={x:(0,r.d9)(e,"x","gather"),indices:(0,r.d9)(t,"indices","gather","int32")},o={axis:n,batchDims:a};return r.db.runKernel(r.b4,s,o)}}),qe=(0,r.w)({greater_:function(e,t){let n=(0,r.d9)(e,"a","greater","string_or_numeric"),a=(0,r.d9)(t,"b","greater","string_or_numeric");[n,a]=(0,r.da)(n,a),(0,r.dm)(n.shape,a.shape);const s={a:n,b:a};return r.db.runKernel(r.b6,s)}}),Ge=(0,r.w)({greaterEqual_:function(e,t){let n=(0,r.d9)(e,"a","greaterEqual","string_or_numeric"),a=(0,r.d9)(t,"b","greaterEqual","string_or_numeric");[n,a]=(0,r.da)(n,a),(0,r.dm)(n.shape,a.shape);const s={a:n,b:a};return r.db.runKernel(r.b7,s)}}),Fe=(0,r.w)({imag_:function(e){const t={input:(0,r.d9)(e,"input","imag")};return r.db.runKernel(r.ba,t)}}),Pe=(0,r.w)({isFinite_:function(e){const t={x:(0,r.d9)(e,"x","isFinite")};return r.db.runKernel(r.bb,t)}}),Be=(0,r.w)({isInf_:function(e){const t={x:(0,r.d9)(e,"x","isInf")};return r.db.runKernel(r.bc,t)}}),Oe=(0,r.w)({isNaN_:function(e){const t={x:(0,r.d9)(e,"x","isNaN")};return r.db.runKernel(r.bd,t)}}),Ve=(0,r.w)({less_:function(e,t){let n=(0,r.d9)(e,"a","less","string_or_numeric"),a=(0,r.d9)(t,"b","less","string_or_numeric");[n,a]=(0,r.da)(n,a),(0,r.dm)(n.shape,a.shape);const s={a:n,b:a};return r.db.runKernel(r.bf,s)}}),He=(0,r.w)({lessEqual_:function(e,t){let n=(0,r.d9)(e,"a","lessEqual","string_or_numeric"),a=(0,r.d9)(t,"b","lessEqual","string_or_numeric");[n,a]=(0,r.da)(n,a),(0,r.dm)(n.shape,a.shape);const s={a:n,b:a};return r.db.runKernel(r.bg,s)}});function Le(e,t,n){if(n<=0)throw new Error("The number of values should be positive.");const a={start:e,stop:t,num:n};return r.db.runKernel(r.bh,{},a)}const je=(0,r.w)({localResponseNormalization_:function(e,t=5,n=1,a=1,s=.5){const o=(0,r.d9)(e,"x","localResponseNormalization");(0,r.cQ)(4===o.rank||3===o.rank,(()=>`Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${o.rank}.`)),(0,r.cQ)((0,r.dk)(t),(()=>`Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${t}.`));let i=o,u=!1;3===o.rank&&(u=!0,i=(0,r.k)(o,[1,o.shape[0],o.shape[1],o.shape[2]]));const c={x:i},l={depthRadius:t,bias:n,alpha:a,beta:s},d=r.db.runKernel(r.bo,c,l);return u?(0,r.k)(d,[d.shape[1],d.shape[2],d.shape[3]]):d}}),Ue=(0,r.w)({log_:function(e){const t={x:(0,r.d9)(e,"x","log")};return r.db.runKernel(r.bi,t)}}),Ye=(0,r.w)({log1p_:function(e){const t={x:(0,r.d9)(e,"x","log1p")};return r.db.runKernel(r.bj,t)}});function Je(e){return(0,r.cQ)((0,r.dn)(e),(()=>"The f passed in grad(f) must be a function")),(t,n)=>{const a=(0,r.d9)(t,"x","tf.grad","string_or_numeric"),s=null!=n?(0,r.d9)(n,"dy","tf.grad"):null;return r.db.tidy((()=>{const{value:t,grads:n}=r.db.gradients((()=>e(a)),[a],s);return null!=s&&(0,r.dp)(t.shape,s.shape,"The shape of dy passed in grad(f)(x, dy) must match the shape returned by f(x)"),rt(n),n[0]}))}}function Ze(e){return(0,r.cQ)((0,r.dn)(e),(()=>"The f passed in grads(f) must be a function")),(t,n)=>{(0,r.cQ)(Array.isArray(t),(()=>"The args passed in grads(f)(args) must be an array of `Tensor`s or `TensorLike`s"));const a=(0,r.dl)(t,"args","tf.grads","string_or_numeric"),s=null!=n?(0,r.d9)(n,"dy","tf.grads"):null;return r.db.tidy((()=>{const{value:t,grads:n}=r.db.gradients((()=>e(...a)),a,s);return null!=s&&(0,r.dp)(t.shape,s.shape,"The shape of dy passed in grads(f)([x1,...], dy) must match the shape returned by f([x1,...])"),rt(n),n}))}}function Xe(e){return(0,r.cQ)((0,r.dn)(e),(()=>"The f passed in valueAndGrad(f) must be a function")),(t,n)=>{(0,r.cQ)(t instanceof r.T,(()=>"The x passed in valueAndGrad(f)(x) must be a tensor")),(0,r.cQ)(null==n||n instanceof r.T,(()=>"The dy passed in valueAndGrad(f)(x, dy) must be a tensor"));const{grads:a,value:s}=r.db.gradients((()=>e(t)),[t],n);return rt(a),{grad:a[0],value:s}}}function et(e){return(0,r.cQ)((0,r.dn)(e),(()=>"The f passed in valueAndGrads(f) must be a function")),(t,n)=>{(0,r.cQ)(Array.isArray(t)&&t.every((e=>e instanceof r.T)),(()=>"The args passed in valueAndGrads(f)(args) must be array of tensors")),(0,r.cQ)(null==n||n instanceof r.T,(()=>"The dy passed in valueAndGrads(f)(args, dy) must be a tensor"));const a=r.db.gradients((()=>e(...t)),t,n);return null!=n&&(0,r.dp)(a.value.shape,n.shape,"The shape of dy passed in valueAndGrads(f)([x1,...], dy) must match the shape returned by f([x1,...])"),rt(a.grads),a}}function tt(e,t){(0,r.cQ)((0,r.dn)(e),(()=>"The f passed in variableGrads(f) must be a function")),(0,r.cQ)(null==t||Array.isArray(t)&&t.every((e=>e instanceof r.V)),(()=>"The varList passed in variableGrads(f, varList) must be an array of variables"));const n=null!=t;if(!n){t=[];for(const e in r.db.registeredVariables)t.push(r.db.registeredVariables[e])}const a=n?t.filter((e=>!e.trainable)):null,s=t.length;t=t.filter((e=>e.trainable)),(0,r.cQ)(t.length>0,(()=>`variableGrads() expects at least one of the input variables to be trainable, but none of the ${s} variables is trainable.`));const{value:o,grads:i}=r.db.gradients(e,t,null,!0);(0,r.cQ)(i.some((e=>null!=e)),(()=>"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().")),(0,r.cQ)(0===o.rank,(()=>`The f passed in variableGrads(f) must return a scalar, but it returned a rank-${o.rank} tensor`));const u={};return t.forEach(((e,t)=>{null!=i[t]&&(u[e.name]=i[t])})),null!=a&&a.forEach((e=>u[e.name]=null)),{value:o,grads:u}}function nt(e){return r.db.customGrad(e)}function rt(e){if(e.filter((e=>null==e)).length>0)throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that\n    the f you passed encloses all operations that lead from x to y.")}const at=(0,r.w)({neg_:function(e){const t={x:(0,r.d9)(e,"x","neg")};return r.db.runKernel(r.bE,t)}}),st=(0,r.w)({softplus_:function(e){const t={x:(0,r.d9)(e,"x","softplus")};return r.db.runKernel(r.ca,t)}}),ot=(0,r.w)({logSigmoid_:function(e){const t=(0,r.d9)(e,"x","logSigmoid");return nt((e=>({value:at(st(at(e))),gradFunc:t=>(0,r.m)(t,(0,r.o)(at(e)))})))(t)}}),it=(0,r.w)({max_:function(e,t=null,n=!1){const a={x:(0,r.d9)(e,"x","max")},s={reductionIndices:t,keepDims:n};return r.db.runKernel(r.bq,a,s)}}),ut=(0,r.w)({sub_:function(e,t){let n=(0,r.d9)(e,"a","sub"),a=(0,r.d9)(t,"b","sub");[n,a]=(0,r.da)(n,a);const s={a:n,b:a};return r.db.runKernel(r.cr,s)}}),ct=(0,r.w)({logSoftmax_:function(e,t=-1){const n=(0,r.d9)(e,"logits","logSoftmax");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and axis was ${t}`);return nt(((e,n)=>{const a=it(e,t,!0),s=ut(e,a),o=ut((0,r.d)(s,"float32"),Ue((0,r.t)(Ae(s),t,!0)));return n([o]),{value:o,gradFunc:(e,n)=>{const[a]=n,s=Ae(a);return ut(e,(0,r.m)((0,r.t)(e,t,!0),s))}}}))(n)}}),lt=(0,r.w)({logSumExp_:function(e,t=null,n=!1){const a=(0,r.d9)(e,"x","logSumExp"),s=(0,r.dq)(t,a.shape),o=it(a,s,!0),i=ut(a,o),u=Ae(i),c=(0,r.t)(u,s),l=Ue(c),d=M((0,r.k)(o,l.shape),l);if(n){const e=(0,r.dr)(d.shape,s);return(0,r.k)(d,e)}return d}}),dt=(0,r.w)({logicalAnd_:function(e,t){const n=(0,r.d9)(e,"a","logicalAnd","bool"),a=(0,r.d9)(t,"b","logicalAnd","bool");(0,r.dm)(n.shape,a.shape);const s={a:n,b:a};return r.db.runKernel(r.bk,s)}}),ht=(0,r.w)({logicalNot_:function(e){const t={x:(0,r.d9)(e,"x","logicalNot","bool")};return r.db.runKernel(r.bl,t)}}),pt=(0,r.w)({logicalOr_:function(e,t){const n=(0,r.d9)(e,"a","logicalOr","bool"),a=(0,r.d9)(t,"b","logicalOr","bool");(0,r.dm)(n.shape,a.shape);const s={a:n,b:a};return r.db.runKernel(r.bm,s)}}),mt=(0,r.w)({logicalXor_:function(e,t){const n=(0,r.d9)(e,"a","logicalXor","bool"),a=(0,r.d9)(t,"b","logicalXor","bool");return(0,r.dm)(n.shape,a.shape),dt(pt(e,t),ht(dt(e,t)))}}),ft=(0,r.w)({maxPool_:function(e,t,n,a,s){const o=(0,r.d9)(e,"x","maxPool");let i=o,u=!1;3===o.rank&&(u=!0,i=(0,r.k)(o,[1,o.shape[0],o.shape[1],o.shape[2]])),(0,r.cQ)(4===i.rank,(()=>`Error in maxPool: input must be rank 4 but got rank ${i.rank}.`)),(0,r.cQ)((0,r.dj)(n,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`)),null!=s&&(0,r.cQ)((0,r.dk)(a),(()=>`Error in maxPool: pad must be an integer when using, dimRoundingMode ${s} but got pad ${a}.`));const c={x:i},l={filterSize:t,strides:n,pad:a,dimRoundingMode:s},d=r.db.runKernel(r.bs,c,l);return u?(0,r.k)(d,[d.shape[1],d.shape[2],d.shape[3]]):d}}),bt=(0,r.w)({maxPool3d_:function(e,t=[1,1,1],n,a,s,o="NDHWC"){const i=(0,r.d9)(e,"x","maxPool3d");let u=i,c=!1;4===i.rank&&(c=!0,u=(0,r.k)(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),(0,r.cQ)(5===u.rank,(()=>`Error in maxPool3d: x must be rank 5 but got rank ${u.rank}.`)),(0,r.cQ)("NDHWC"===o,(()=>`Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${o}`)),null!=s&&(0,r.cQ)((0,r.dk)(a),(()=>`Error in maxPool3d: pad must be an integer when using, dimRoundingMode ${s} but got pad ${a}.`));const l={x:u},d={filterSize:t,strides:n,pad:a,dimRoundingMode:s,dataFormat:o},h=r.db.runKernel(r.bu,l,d);return c?(0,r.k)(h,[h.shape[1],h.shape[2],h.shape[3],h.shape[4]]):h}}),gt=(0,r.w)({maxPoolWithArgmax_:function(e,t,n,a,s=!1){const o={x:(0,r.d9)(e,"x","maxPoolWithArgmax")},i={filterSize:t,strides:n,pad:a,includeBatchInIndex:s},u=r.db.runKernel(r.bw,o,i);return{result:u[0],indexes:u[1]}}}),wt=(0,r.w)({maximum_:function(e,t){let n=(0,r.d9)(e,"a","maximum"),a=(0,r.d9)(t,"b","maximum");[n,a]=(0,r.da)(n,a),"bool"===n.dtype&&(n=(0,r.d)(n,"int32"),a=(0,r.d)(a,"int32")),(0,r.dm)(n.shape,a.shape);const s={a:n,b:a};return r.db.runKernel(r.br,s)}}),kt=(0,r.w)({mean_:function(e,t=null,n=!1){const a={x:(0,r.d9)(e,"x","mean")},s={axis:t,keepDims:n};return r.db.runKernel(r.bx,a,s)}});function xt(e,t="float32"){if("complex64"===t){const t=xt(e,"float32"),n=(0,r.z)(e,"float32");return(0,r.g)(t,n)}const n=(0,r.ds)((0,r.dt)(e),t);return r.db.makeTensor(n,e,t)}function vt(e,t,{indexing:n="xy"}={}){if("xy"!==n&&"ij"!==n)throw new TypeError(`${n} is not a valid third argument to meshgrid`);if(void 0===e)return[];let a=(0,r.d9)(e,"x","meshgrid",e instanceof r.T?e.dtype:"float32");if(void 0===t)return[a];let s=(0,r.d9)(t,"y","meshgrid",t instanceof r.T?t.dtype:"float32");const o=(0,r.dt)(a.shape),i=(0,r.dt)(s.shape);return"xy"===n?(a=(0,r.k)(a,[1,-1]),s=(0,r.k)(s,[-1,1]),[u(xt([i,1],a.dtype),a),u(s,xt([1,o],s.dtype))]):(a=(0,r.k)(a,[-1,1]),s=(0,r.k)(s,[1,-1]),[u(a,xt([1,i],a.dtype)),u(xt([o,1],s.dtype),s)])}const yt=(0,r.w)({min_:function(e,t=null,n=!1){const a={x:(0,r.d9)(e,"x","min")},s={axis:t,keepDims:n};return r.db.runKernel(r.by,a,s)}}),Et=(0,r.w)({minimum_:function(e,t){let n=(0,r.d9)(e,"a","minimum"),a=(0,r.d9)(t,"b","minimum");[n,a]=(0,r.da)(n,a),"bool"===n.dtype&&(n=(0,r.d)(n,"int32"),a=(0,r.d)(a,"int32")),(0,r.dm)(n.shape,a.shape);const s={a:n,b:a};return r.db.runKernel(r.bz,s)}}),$t=(0,r.w)({mirrorPad_:function(e,t,n){(0,r.cQ)("reflect"===n||"symmetric"===n,(()=>`Invalid mode. Mode must be either reflect or symmetric. Got ${n}.`));const a=(0,r.d9)(e,"x","mirrorPad");if(0===a.rank)throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");(0,r.cQ)(t.length===a.rank,(()=>`Padding doesn't match input. Must be ${a.rank}. Got ${t.length}.`));const s="reflect"===n?1:0;for(let e=0;e<a.rank;e++)(0,r.cQ)(2===t[e].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),(0,r.cQ)(t[e][0]>=0&&t[e][0]<=a.shape[e]-s&&t[e][1]>=0&&t[e][1]<=a.shape[e]-s,(()=>`Padding in dimension ${e} cannot be greater than or equal to ${a.shape[e]-s} or less than 0 for input of shape ${a.shape}`));const o={paddings:t,mode:n},i={x:a};return r.db.runKernel(r.bA,i,o)}}),_t=(0,r.w)({mod_:function(e,t){let n=(0,r.d9)(e,"a","mod"),a=(0,r.d9)(t,"b","mod");[n,a]=(0,r.da)(n,a);const s={a:n,b:a};return r.db.runKernel(r.bB,s)}}),Nt=(0,r.w)({square_:function(e){const t=(0,r.d9)(e,"x","square");return r.db.runKernel("Square",{x:t},{})}}),St=(0,r.w)({moments_:function(e,t=null,n=!1){e=(0,r.d9)(e,"x","moments");const a=(0,r.dq)(t,e.shape),s=kt(e,a,n);let o=s.shape;n||(o=(0,r.dr)(s.shape,a));const i=Nt(ut((0,r.d)(e,"float32"),(0,r.k)(s,o)));return{mean:s,variance:kt(i,a,n)}}}),Mt=(0,r.w)({multiRNNCell_:function(e,t,n,a){const s=(0,r.d9)(t,"data","multiRNNCell"),o=(0,r.dl)(n,"c","multiRNNCell"),i=(0,r.dl)(a,"h","multiRNNCell");let u=s;const c=[];for(let t=0;t<e.length;t++){const n=e[t](u,o[t],i[t]);c.push(n[0]),c.push(n[1]),u=n[1]}const l=[],d=[];for(let e=0;e<c.length;e+=2)l.push(c[e]),d.push(c[e+1]);return[l,d]}}),Qt=(0,r.w)({multinomial_:function(e,t,n,a=!1){const s=(0,r.d9)(e,"logits","multinomial"),o=s.size,i=s.rank;if(o<2)throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${o}.`);if(i>2)throw new Error(`Rank of probabilities must be 1 or 2, but is ${i}`);n=n||Math.random();const u={logits:1===i?(0,r.k)(s,[1,-1]):s},c={numSamples:t,seed:n,normalized:a},l=r.db.runKernel(r.bC,u,c);return 1===i?(0,r.k)(l,[l.size]):l}}),It=(0,r.w)({notEqual_:function(e,t){let n=(0,r.d9)(e,"a","notEqual","string_or_numeric"),a=(0,r.d9)(t,"b","notEqual","string_or_numeric");[n,a]=(0,r.da)(n,a),(0,r.dm)(n.shape,a.shape);const s={a:n,b:a};return r.db.runKernel(r.bF,s)}}),At=(0,r.w)({onesLike_:function(e){const t={x:(0,r.d9)(e,"x","onesLike")};return r.db.runKernel(r.bJ,t)}}),Tt=(0,r.w)({outerProduct_:function(e,t){const n=(0,r.d9)(e,"v1","outerProduct"),a=(0,r.d9)(t,"v2","outerProduct");(0,r.cQ)(1===n.rank&&1===a.rank,(()=>`Error in outerProduct: inputs must be rank 1, but got ranks ${n.rank} and ${a.rank}.`));const s=(0,r.k)(n,[-1,1]),o=(0,r.k)(a,[1,-1]);return u(s,o)}}),Ct=(0,r.w)({pad_:function(e,t,n=0){const a=(0,r.d9)(e,"x","pad");if(0===a.rank)throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");const s={paddings:t,constantValue:n},o={x:a};return r.db.runKernel(r.bM,o,s)}}),Dt=(0,r.w)({pad1d_:function(e,t,n=0){return(0,r.cQ)(2===t.length,(()=>"Invalid number of paddings. Must be length of 2.")),Ct(e,[t],n)}}),Kt=(0,r.w)({pad2d_:function(e,t,n=0){return(0,r.cQ)(2===t.length&&2===t[0].length&&2===t[1].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),Ct(e,t,n)}}),zt=(0,r.w)({pad3d_:function(e,t,n=0){return(0,r.cQ)(3===t.length&&2===t[0].length&&2===t[1].length&&2===t[2].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),Ct(e,t,n)}}),Rt=(0,r.w)({pad4d_:function(e,t,n=0){return(0,r.cQ)(4===t.length&&2===t[0].length&&2===t[1].length&&2===t[2].length&&2===t[3].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),Ct(e,t,n)}}),Wt=(0,r.w)({spaceToBatchND_:function(e,t,n){const a=(0,r.d9)(e,"x","spaceToBatchND");(0,r.cQ)(a.rank>=1+t.length,(()=>`input rank ${a.rank} should be > than [blockShape] ${t.length}`)),(0,r.cQ)(n.length===t.length,(()=>`paddings.shape[0] ${n.length} must be equal to [blockShape] ${t.length}`)),(0,r.cQ)(a.shape.reduce(((e,r,a)=>a>0&&a<=t.length?e&&(r+n[a-1][0]+n[a-1][1])%t[a-1]==0:e),!0),(()=>`input spatial dimensions ${a.shape.slice(1)} with paddings ${n.toString()} must be divisible by blockShapes ${t.toString()}`));const s={x:a},o={blockShape:t,paddings:n};return r.db.runKernel(r.cd,s,o)}}),qt=(0,r.w)({pool_:function(e,t,n,a,s,o){null==s&&(s=[1,1]),null==o&&(o=1),0===a&&(a="valid");const i=(0,r.d9)(e,"x","maxPool");let u=i,c=!1;3===i.rank&&(c=!0,u=(0,r.k)(i,[1,i.shape[0],i.shape[1],i.shape[2]])),(0,r.cQ)((0,r.dj)(o,s),(()=>`Error in pool: Either strides or dilations must be 1. Got strides ${o} and dilations '${s}'`));const l=(0,r.du)(u.shape,t,o,s,a),d=[l.dilationHeight,l.dilationWidth];let h;h="same"===a?function(e,t){const n=e.map(((e,n)=>e+(e-1)*(t[n]-1))).map((e=>e-1)),r=n.map((e=>Math.floor(e/2))),a=n.map(((e,t)=>e-r[t]));return n.map(((e,t)=>[r[t],a[t]]))}([l.filterHeight,l.filterWidth],d):[[0,0],[0,0]];const p=1===d[0]&&1===d[1],[m,f]=function(e,t,n){const r=n.map((e=>e[0])),a=n.map((e=>e[1])),s=e.concat(r,a),o=t.map(((e,t)=>(e-s[t]%e)%e)),i=a.map(((e,t)=>e+o[t]));return[t.map(((e,t)=>[r[t],i[t]])),t.map(((e,t)=>[0,o[t]]))]}([l.inHeight,l.inWidth],d,h),b=p?a:"valid",g=p?u:Wt(u,d,m),w=("avg"===n?()=>O(g,t,o,b):()=>ft(g,t,o,b))(),k=p?w:Y(w,d,f);return c?(0,r.k)(k,[k.shape[1],k.shape[2],k.shape[3]]):k}}),Gt=(0,r.w)({pow_:function(e,t){let n=(0,r.d9)(e,"base","pow"),a=(0,r.d9)(t,"exp","pow");[n,a]=(0,r.da)(n,a);const s={a:n,b:a};return r.db.runKernel(r.bO,s)}}),Ft=(0,r.w)({prod_:function(e,t=null,n=!1){let a=(0,r.d9)(e,"x","prod");"bool"===a.dtype&&(a=(0,r.d)(a,"int32"));const s={x:a},o={axis:t,keepDims:n};return r.db.runKernel(r.bQ,s,o)}}),Pt=(0,r.w)({rand_:function(e,t,n){const a=(0,r.dt)(e);let s=null;if(null==n||"float32"===n)s=new Float32Array(a);else if("int32"===n)s=new Int32Array(a);else{if("bool"!==n)throw new Error(`Unknown data type ${n}`);s=new Uint8Array(a)}for(let e=0;e<a;e++)s[e]=t();return r.db.makeTensor(s,e,n)}});var Bt=(0,a.c)((function(e){!function(e,t,n){function r(e){var t,n=this,r=(t=4022871197,function(e){e=e.toString();for(var n=0;n<e.length;n++){var r=.02519603282416938*(t+=e.charCodeAt(n));r-=t=r>>>0,t=(r*=t)>>>0,t+=4294967296*(r-=t)}return 2.3283064365386963e-10*(t>>>0)});n.next=function(){var e=2091639*n.s0+2.3283064365386963e-10*n.c;return n.s0=n.s1,n.s1=n.s2,n.s2=e-(n.c=0|e)},n.c=1,n.s0=r(" "),n.s1=r(" "),n.s2=r(" "),n.s0-=r(e),n.s0<0&&(n.s0+=1),n.s1-=r(e),n.s1<0&&(n.s1+=1),n.s2-=r(e),n.s2<0&&(n.s2+=1),r=null}function a(e,t){return t.c=e.c,t.s0=e.s0,t.s1=e.s1,t.s2=e.s2,t}function s(e,t){var n=new r(e),s=t&&t.state,o=n.next;return o.int32=function(){return 4294967296*n.next()|0},o.double=function(){return o()+11102230246251565e-32*(2097152*o()|0)},o.quick=o,s&&("object"==typeof s&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.alea=s}(a.a,e)})),Ot=(0,a.c)((function(e){!function(e,t,n){function r(e){var t=this,n="";t.x=0,t.y=0,t.z=0,t.w=0,t.next=function(){var e=t.x^t.x<<11;return t.x=t.y,t.y=t.z,t.z=t.w,t.w^=t.w>>>19^e^e>>>8},e===(0|e)?t.x=e:n+=e;for(var r=0;r<n.length+64;r++)t.x^=0|n.charCodeAt(r),t.next()}function a(e,t){return t.x=e.x,t.y=e.y,t.z=e.z,t.w=e.w,t}function s(e,t){var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&("object"==typeof s&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.xor128=s}(a.a,e)})),Vt=(0,a.c)((function(e){!function(e,t,n){function r(e){var t=this,n="";t.next=function(){var e=t.x^t.x>>>2;return t.x=t.y,t.y=t.z,t.z=t.w,t.w=t.v,(t.d=t.d+362437|0)+(t.v=t.v^t.v<<4^e^e<<1)|0},t.x=0,t.y=0,t.z=0,t.w=0,t.v=0,e===(0|e)?t.x=e:n+=e;for(var r=0;r<n.length+64;r++)t.x^=0|n.charCodeAt(r),r==n.length&&(t.d=t.x<<10^t.x>>>4),t.next()}function a(e,t){return t.x=e.x,t.y=e.y,t.z=e.z,t.w=e.w,t.v=e.v,t.d=e.d,t}function s(e,t){var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&("object"==typeof s&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.xorwow=s}(a.a,e)})),Ht=(0,a.c)((function(e){!function(e,t,n){function r(e){var t=this;t.next=function(){var e,n,r=t.x,a=t.i;return e=r[a],n=(e^=e>>>7)^e<<24,n^=(e=r[a+1&7])^e>>>10,n^=(e=r[a+3&7])^e>>>3,n^=(e=r[a+4&7])^e<<7,e=r[a+7&7],n^=(e^=e<<13)^e<<9,r[a]=n,t.i=a+1&7,n},function(e,t){var n,r=[];if(t===(0|t))r[0]=t;else for(t=""+t,n=0;n<t.length;++n)r[7&n]=r[7&n]<<15^t.charCodeAt(n)+r[n+1&7]<<13;for(;r.length<8;)r.push(0);for(n=0;n<8&&0===r[n];++n);for(8==n&&(r[7]=-1),e.x=r,e.i=0,n=256;n>0;--n)e.next()}(t,e)}function a(e,t){return t.x=e.x.slice(),t.i=e.i,t}function s(e,t){null==e&&(e=+new Date);var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&(s.x&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.xorshift7=s}(a.a,e)})),Lt=(0,a.c)((function(e){!function(e,t,n){function r(e){var t=this;t.next=function(){var e,n,r=t.w,a=t.X,s=t.i;return t.w=r=r+1640531527|0,n=a[s+34&127],e=a[s=s+1&127],n^=n<<13,e^=e<<17,n^=n>>>15,e^=e>>>12,n=a[s]=n^e,t.i=s,n+(r^r>>>16)|0},function(e,t){var n,r,a,s,o,i=[],u=128;for(t===(0|t)?(r=t,t=null):(t+="\0",r=0,u=Math.max(u,t.length)),a=0,s=-32;s<u;++s)t&&(r^=t.charCodeAt((s+32)%t.length)),0===s&&(o=r),r^=r<<10,r^=r>>>15,r^=r<<4,r^=r>>>13,s>=0&&(o=o+1640531527|0,a=0==(n=i[127&s]^=r+o)?a+1:0);for(a>=128&&(i[127&(t&&t.length||0)]=-1),a=127,s=512;s>0;--s)r=i[a+34&127],n=i[a=a+1&127],r^=r<<13,n^=n<<17,r^=r>>>15,n^=n>>>12,i[a]=r^n;e.w=o,e.X=i,e.i=a}(t,e)}function a(e,t){return t.i=e.i,t.w=e.w,t.X=e.X.slice(),t}function s(e,t){null==e&&(e=+new Date);var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&(s.X&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.xor4096=s}(a.a,e)})),jt=(0,a.c)((function(e){!function(e,t,n){function r(e){var t=this,n="";t.next=function(){var e=t.b,n=t.c,r=t.d,a=t.a;return e=e<<25^e>>>7^n,n=n-r|0,r=r<<24^r>>>8^a,a=a-e|0,t.b=e=e<<20^e>>>12^n,t.c=n=n-r|0,t.d=r<<16^n>>>16^a,t.a=a-e|0},t.a=0,t.b=0,t.c=-1640531527,t.d=1367130551,e===Math.floor(e)?(t.a=e/4294967296|0,t.b=0|e):n+=e;for(var r=0;r<n.length+20;r++)t.b^=0|n.charCodeAt(r),t.next()}function a(e,t){return t.a=e.a,t.b=e.b,t.c=e.c,t.d=e.d,t}function s(e,t){var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&("object"==typeof s&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.tychei=s}(a.a,e)})),Ut=Object.freeze({__proto__:null,default:{}}),Yt=(0,a.g)(Ut),Jt=(0,a.c)((function(e){!function(t,n){var r,a=this,s=256,o=n.pow(s,6),i=n.pow(2,52),u=2*i,c=255;function l(e,c,l){var b=[],g=m(p((c=1==c?{entropy:!0}:c||{}).entropy?[e,f(t)]:null==e?function(){try{var e;return r&&(e=r.randomBytes)?e=e(s):(e=new Uint8Array(s),(a.crypto||a.msCrypto).getRandomValues(e)),f(e)}catch(e){var n=a.navigator,o=n&&n.plugins;return[+new Date,a,o,a.screen,f(t)]}}():e,3),b),w=new d(b),k=function(){for(var e=w.g(6),t=o,n=0;e<i;)e=(e+n)*s,t*=s,n=w.g(1);for(;e>=u;)e/=2,t/=2,n>>>=1;return(e+n)/t};return k.int32=function(){return 0|w.g(4)},k.quick=function(){return w.g(4)/4294967296},k.double=k,m(f(w.S),t),(c.pass||l||function(e,t,r,a){return a&&(a.S&&h(a,w),e.state=function(){return h(w,{})}),r?(n.random=e,t):e})(k,g,"global"in c?c.global:this==n,c.state)}function d(e){var t,n=e.length,r=this,a=0,o=r.i=r.j=0,i=r.S=[];for(n||(e=[n++]);a<s;)i[a]=a++;for(a=0;a<s;a++)i[a]=i[o=c&o+e[a%n]+(t=i[a])],i[o]=t;(r.g=function(e){for(var t,n=0,a=r.i,o=r.j,i=r.S;e--;)t=i[a=c&a+1],n=n*s+i[c&(i[a]=i[o=c&o+t])+(i[o]=t)];return r.i=a,r.j=o,n})(s)}function h(e,t){return t.i=e.i,t.j=e.j,t.S=e.S.slice(),t}function p(e,t){var n,r=[],a=typeof e;if(t&&"object"==a)for(n in e)try{r.push(p(e[n],t-1))}catch(e){}return r.length?r:"string"==a?e:e+"\0"}function m(e,t){for(var n,r=e+"",a=0;a<r.length;)t[c&a]=c&(n^=19*t[c&a])+r.charCodeAt(a++);return f(t)}function f(e){return String.fromCharCode.apply(0,e)}if(n.seedrandom=l,m(n.random(),t),e.exports){e.exports=l;try{r=Yt}catch(e){}}}([],Math)}));Jt.alea=Bt,Jt.xor128=Ot,Jt.xorwow=Vt,Jt.xorshift7=Ht,Jt.xor4096=Lt,Jt.tychei=jt;var Zt=Jt;class Xt{constructor(e,t,n,r,a){this.mean=e,this.stdDev=t,this.dtype=n,this.nextVal=NaN,this.truncated=r,this.truncated&&(this.upper=this.mean+2*this.stdDev,this.lower=this.mean-2*this.stdDev);const s=a||Math.random();this.random=Zt.alea(s.toString())}nextValue(){if(!isNaN(this.nextVal)){const e=this.nextVal;return this.nextVal=NaN,e}let e,t,n=!1;for(;!n;){let r,a,s;do{r=2*this.random()-1,a=2*this.random()-1,s=r*r+a*a}while(s>=1||0===s);const o=Math.sqrt(-2*Math.log(s)/s);e=this.mean+this.stdDev*r*o,t=this.mean+this.stdDev*a*o,this.truncated&&!this.isValidTruncated(e)||(n=!0)}return this.truncated&&!this.isValidTruncated(t)||(this.nextVal=this.convertValue(t)),this.convertValue(e)}convertValue(e){return null==this.dtype||"float32"===this.dtype?e:Math.round(e)}isValidTruncated(e){return e<=this.upper&&e>=this.lower}}class en{constructor(e,t,n,r){this.alpha=e,this.beta=1/t,this.dtype=n;const a=r||Math.random();this.randu=Zt.alea(a.toString()),this.randn=new Xt(0,1,n,!1,this.randu()),this.d=e<1?e+2/3:e-1/3,this.c=1/Math.sqrt(9*this.d)}nextValue(){let e,t,n,r,a,s;for(;;){do{r=this.randn.nextValue(),s=1+this.c*r}while(s<=0);if(s*=s*s,e=r*r,t=1-.331*e*e,n=.5*e+this.d*(1-s+Math.log(s)),a=this.randu(),a<t||Math.log(a)<n)break}return s=1/this.beta*this.d*s,this.alpha<1&&(s*=Math.pow(this.randu(),1/this.alpha)),this.convertValue(s)}convertValue(e){return"float32"===this.dtype?e:Math.round(e)}}class tn{constructor(e=0,t=1,n,r){if(this.canReturnFloat=()=>null==this.dtype||"float32"===this.dtype,this.min=e,this.range=t-e,this.dtype=n,null==r&&(r=Math.random()),"number"==typeof r&&(r=r.toString()),!this.canReturnFloat()&&this.range<=1)throw new Error(`The difference between ${e} - ${t} <= 1 and dtype is not float`);this.random=Zt.alea(r)}convertValue(e){return this.canReturnFloat()?e:Math.round(e)}nextValue(){return this.convertValue(this.min+this.range*this.random())}}const nn=(0,r.w)({randomGamma_:function(e,t,n=1,a="float32",s){if(null==n&&(n=1),null==a&&(a="float32"),"float32"!==a&&"int32"!==a)throw new Error(`Unsupported data type ${a}`);const o=new en(t,n,a,s),i=(0,r.c)(e,a);for(let e=0;e<i.values.length;e++)i.values[e]=o.nextValue();return i.toTensor()}}),rn=(0,r.w)({randomNormal_:function(e,t=0,n=1,a,s){if(null!=a&&"bool"===a)throw new Error(`Unsupported data type ${a}`);const o=new Xt(t,n,a,!1,s),i=(0,r.c)(e,a);for(let e=0;e<i.values.length;e++)i.values[e]=o.nextValue();return i.toTensor()}}),an=(0,r.w)({randomUniform_:function(e,t=0,n=1,a="float32",s){const o=(0,r.c)(e,a),i=new tn(t,n,null,s);for(let e=0;e<o.values.length;e++)o.values[e]=i.nextValue();return o.toTensor()}});function sn(e,t,n=1,a="float32"){if(0===n)throw new Error("Cannot have a step of zero");const s={start:e,stop:t,step:n,dtype:a};return r.db.runKernel(r.bR,{},s)}const on=(0,r.w)({real_:function(e){const t={input:(0,r.d9)(e,"input","real")};return r.db.runKernel(r.bS,t)}}),un=(0,r.w)({reciprocal_:function(e){const t={x:(0,r.d9)(e,"x","reciprocal")};return r.db.runKernel(r.bT,t)}}),cn=(0,r.w)({reverse_:function(e,t){const n={x:(0,r.d9)(e,"x","reverse")},a={dims:t};return r.db.runKernel(r.b$,n,a)}}),ln=(0,r.w)({reverse1d_:function(e){const t=(0,r.d9)(e,"x","reverse");return(0,r.cQ)(1===t.rank,(()=>`Error in reverse1D: x must be rank 1 but got rank ${t.rank}.`)),cn(t,0)}}),dn=(0,r.w)({reverse2d_:function(e,t){const n=(0,r.d9)(e,"x","reverse");return(0,r.cQ)(2===n.rank,(()=>`Error in reverse2D: x must be rank 2 but got rank ${n.rank}.`)),cn(n,t)}}),hn=(0,r.w)({reverse3d_:function(e,t){const n=(0,r.d9)(e,"x","reverse");return(0,r.cQ)(3===n.rank,(()=>`Error in reverse3D: x must be rank 3 but got rank ${n.rank}.`)),cn(n,t)}}),pn=(0,r.w)({reverse4d_:function(e,t){const n=(0,r.d9)(e,"x","reverse");return(0,r.cQ)(4===n.rank,(()=>`Error in reverse4D: x must be rank 4 but got rank ${n.rank}.`)),cn(n,t)}}),mn=(0,r.w)({round_:function(e){const t={x:(0,r.d9)(e,"x","round")};return r.db.runKernel(r.c0,t)}}),fn=(0,r.w)({rsqrt_:function(e){const t={x:(0,r.d9)(e,"x","rsqrt")};return r.db.runKernel(r.c1,t)}}),bn=(0,r.w)({selu_:function(e){const t={x:(0,r.d9)(e,"x","selu")};return r.db.runKernel(r.c4,t)}}),gn=(0,r.w)({separableConv2d_:function(e,t,n,a,s,o=[1,1],i="NHWC"){const u=(0,r.d9)(e,"x","separableConv2d"),c=(0,r.d9)(t,"depthwiseFilter","separableConv2d"),l=(0,r.d9)(n,"pointwiseFilter","separableConv2d");let d=u,h=!1;if(3===u.rank&&(h=!0,d=(0,r.k)(u,[1,u.shape[0],u.shape[1],u.shape[2]])),"NCHW"===i)throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");(0,r.cQ)(4===d.rank,(()=>`Error in separableConv2d: input must be rank 4, but got rank ${d.rank}.`)),(0,r.cQ)(4===c.rank,(()=>`Error in separableConv2d: depthwise filter must be rank 4, but got rank ${c.rank}.`)),(0,r.cQ)(4===l.rank,(()=>`Error in separableConv2d: pointwise filter must be rank 4, but got rank ${c.rank}.`)),(0,r.cQ)(1===l.shape[0],(()=>`Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${l.shape[0]}.`)),(0,r.cQ)(1===l.shape[1],(()=>`Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${l.shape[1]}.`));const p=c.shape[2],m=c.shape[3];(0,r.cQ)(l.shape[2]===p*m,(()=>`Error in separableConv2d: the third dimension of pointwise filter must be ${p*m}, but got ${l.shape[2]}.`));const f=ve(d,c,a,s,i,o),b=ce(f,l,1,"valid",i);return h?(0,r.k)(b,[b.shape[1],b.shape[2],b.shape[3]]):b}}),wn=async function(e,t){const n=(0,r.d9)(e,"x","setdiff1d"),a=(0,r.d9)(t,"y","setdiff1d");(0,r.cQ)(n.dtype===a.dtype,(()=>`x and y should have the same dtype, but got x (${n.dtype}) and y (${a.dtype}).`)),(0,r.cQ)(1===n.rank,(()=>`x should be 1D tensor, but got x (${n.shape}).`)),(0,r.cQ)(1===a.rank,(()=>`y should be 1D tensor, but got y (${a.shape}).`));const s=await n.data(),o=await a.data(),i=new Set(o);let u=0;for(let e=0;e<s.length;e++)i.has(s[e])||u++;const c=new r.a([u],n.dtype),l=new r.a([u],"int32");for(let e=0,t=0;e<s.length;e++)i.has(s[e])||(c.values[t]=s[e],l.values[t]=e,t++);return[c.toTensor(),l.toTensor()]},kn=(0,r.w)({sign_:function(e){const t={x:(0,r.d9)(e,"x","sign")};return r.db.runKernel(r.c8,t)}}),xn=(0,r.w)({sin_:function(e){const t={x:(0,r.d9)(e,"x","sin")};return r.db.runKernel(r.c6,t)}}),vn=(0,r.w)({sinh_:function(e){const t={x:(0,r.d9)(e,"x","sinh")};return r.db.runKernel(r.c7,t)}}),yn=(0,r.w)({slice1d_:function(e,t,n){const a=(0,r.d9)(e,"x","slice1d");return(0,r.cQ)(1===a.rank,(()=>`slice1d expects a rank-1 tensor, but got a rank-${a.rank} tensor`)),L(a,[t],[n])}}),En=(0,r.w)({slice2d_:function(e,t,n){const a=(0,r.d9)(e,"x","slice2d");return(0,r.cQ)(2===a.rank,(()=>`slice2d expects a rank-2 tensor, but got a rank-${a.rank} tensor`)),L(a,t,n)}}),$n=(0,r.w)({slice3d_:function(e,t,n){const a=(0,r.d9)(e,"x","slice3d");return(0,r.cQ)(3===a.rank,(()=>`slice3d expects a rank-3 tensor, but got a rank-${a.rank} tensor`)),L(a,t,n)}}),_n=(0,r.w)({slice4d_:function(e,t,n){const a=(0,r.d9)(e,"x","slice4d");return(0,r.cQ)(4===a.rank,(()=>`slice4d expects a rank-4 tensor, but got a rank-${a.rank} tensor`)),L(a,t,n)}}),Nn=(0,r.w)({softmax_:function(e,t=-1){const n=(0,r.d9)(e,"logits","softmax","float32");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and dim was ${t}`);const a={logits:n},s={dim:t};return r.db.runKernel(r.cf,a,s)}}),Sn=(0,r.w)({fft_:function(e){(0,r.cQ)("complex64"===e.dtype,(()=>`The dtype for tf.spectral.fft() must be complex64 but got ${e.dtype}.`));const t={input:e};return r.db.runKernel(r.a_,t)}}),Mn=(0,r.w)({ifft_:function(e){(0,r.cQ)("complex64"===e.dtype,(()=>`The dtype for tf.spectral.ifft() must be complex64 but got ${e.dtype}.`));const t={input:e};return r.db.runKernel(r.b9,t)}}),Qn=(0,r.w)({irfft_:function(e){const t=e.shape[e.shape.length-1],n=e.size/t;let a;if(t<=2){const s=(0,r.k)(e,[n,t]);a=Mn(s)}else{const s=[n,2*(t-1)],o=(0,r.k)(on(e),[n,t]),i=(0,r.k)(Fe(e),[n,t]),u=cn(L(o,[0,1],[n,t-2]),1),c=(0,r.m)(cn(L(i,[0,1],[n,t-2]),1),(0,r.n)(-1)),l=H([o,u],1),d=H([i,c],1),h=(0,r.k)((0,r.g)(l,d),[s[0],s[1]]);a=Mn(h)}if(a=on(a),3===e.rank&&0!==e.shape[0]){const t=a,n=e.shape[0];a=(0,r.k)(a,[n,a.shape[0]/n,a.shape[1]]),t.dispose()}return a}}),In=(0,r.w)({split_:function(e,t,n=0){const a={x:(0,r.d9)(e,"x","split")},s={numOrSizeSplits:t,axis:n};return r.db.runKernel(r.ce,a,s)}}),An=(0,r.w)({rfft_:function(e,t){(0,r.cQ)("float32"===e.dtype,(()=>`The dtype for rfft() must be real value but got ${e.dtype}`));let n=e.shape[e.shape.length-1];const a=e.size/n;let s;if(null!=t&&t<n){const r=e.shape.map((e=>0)),a=e.shape.map((e=>e));a[e.shape.length-1]=t,s=L(e,r,a),n=t}else if(null!=t&&t>n){const a=e.shape.map((e=>e));a[e.shape.length-1]=t-n,s=H([e,(0,r.z)(a)],e.shape.length-1),n=t}else s=e;const o=Ne(s),i=(0,r.k)((0,r.g)(s,o),[a,n]),u=Sn(i),c=Math.floor(n/2)+1,l=on(u),d=Fe(u),h=In(l,[c,n-c],l.shape.length-1),p=In(d,[c,n-c],d.shape.length-1),m=s.shape.slice();return m[s.shape.length-1]=c,(0,r.k)((0,r.g)(h[0],p[0]),m)}}),Tn=(0,r.w)({sqrt_:function(e){const t={x:(0,r.d9)(e,"x","sqrt")};return r.db.runKernel(r.cb,t)}}),Cn=(0,r.w)({squaredDifference_:function(e,t){let n=(0,r.d9)(e,"a","squaredDifference"),a=(0,r.d9)(t,"b","squaredDifference");[n,a]=(0,r.da)(n,a),(0,r.dm)(n.shape,a.shape);const s={a:n,b:a};return r.db.runKernel(r.cl,s,{})}}),Dn=(0,r.w)({squeeze_:function(e,t){const n=(0,r.d9)(e,"x","squeeze");return(0,r.k)(n,(0,r.dv)(n.shape,t).newShape)}}),Kn=(0,r.w)({stack_:function(e,t=0){const n=(0,r.dl)(e,"tensors","stack","string_or_numeric");(0,r.cQ)(n.length>=1,(()=>"Pass at least one tensor to tf.stack")),n.length>0&&(0,r.cQ)(t<=n[0].rank,(()=>"Axis must be <= rank of the tensor"));const a=n,s={axis:t};return r.db.runKernel(r.bL,a,s)}}),zn=(0,r.w)({stridedSlice_:function(e,t,n,a,s=0,o=0,i=0,u=0,c=0){const l={x:(0,r.d9)(e,"x","stridedSlice","string_or_numeric")},d={begin:t,end:n,strides:a,beginMask:s,endMask:o,ellipsisMask:i,newAxisMask:u,shrinkAxisMask:c};return r.db.runKernel(r.cn,l,d)}}),Rn=(0,r.w)({tan_:function(e){const t={x:(0,r.d9)(e,"x","tan")};return r.db.runKernel(r.cs,t)}});function Wn(e,t){(0,r.dc)(e);const n=(0,r.dd)(e,t);if(1!==n.length)throw new Error("tensor1d() requires values to be a flat/TypedArray");return(0,r.de)(e,null,n,t)}function qn(e,t,n){if((0,r.dc)(e),null!=t&&2!==t.length)throw new Error("tensor2d() requires shape to have two numbers");const a=(0,r.dd)(e,n);if(2!==a.length&&1!==a.length)throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");if(1===a.length&&null==t)throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");return(0,r.de)(e,t,a,n)}function Gn(e,t,n){if((0,r.dc)(e),null!=t&&4!==t.length)throw new Error("tensor4d() requires shape to have four numbers");const a=(0,r.dd)(e,n);if(4!==a.length&&1!==a.length)throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");if(1===a.length&&null==t)throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");return(0,r.de)(e,t,a,n)}function Fn(e,t,n){if((0,r.dc)(e),null!=t&&5!==t.length)throw new Error("tensor5d() requires shape to have five numbers");const a=(0,r.dd)(e,n);if(5!==a.length&&1!==a.length)throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");if(1===a.length&&null==t)throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");return(0,r.de)(e,t,a,n)}function Pn(e,t,n){if((0,r.dc)(e),null!=t&&6!==t.length)throw new Error("tensor6d() requires shape to have six numbers");const a=(0,r.dd)(e,n);if(6!==a.length&&1!==a.length)throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");if(1===a.length&&null==t)throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");return t=t||a,(0,r.de)(e,t,a,n)}const Bn=(0,r.w)({topk_:function(e,t=1,n=!0){const a=(0,r.d9)(e,"x","topk");if(0===a.rank)throw new Error("topk() expects the input to be of rank 1 or higher");const s=a.shape[a.shape.length-1];if(t>s)throw new Error(`'k' passed to topk() must be <= the last dimension (${s}) but got ${t}`);const o={x:a},i={k:t,sorted:n},[u,c]=r.db.runKernel(r.cv,o,i);return{values:u,indices:c}}}),On=(0,r.w)({truncatedNormal_:function(e,t=0,n=1,a,s){if(null!=a&&"bool"===a)throw new Error("Unsupported data type $ { dtype }");const o=new Xt(t,n,a,!0,s),i=(0,r.c)(e,a);for(let e=0;e<i.values.length;e++)i.values[e]=o.nextValue();return i.toTensor()}}),Vn=(0,r.w)({unique_:function(e,t=0){const n=(0,r.d9)(e,"x","unique","string_or_numeric");(0,r.cQ)(n.rank>0,(()=>"The input tensor must be at least 1D"));const a={x:n},s={axis:t},[o,i]=r.db.runKernel(r.cy,a,s);return{values:o,indices:i}}}),Hn=(0,r.w)({unsortedSegmentSum_:function(e,t,n){const a=(0,r.d9)(e,"x","unsortedSegmentSum"),s=(0,r.d9)(t,"segmentIds","unsortedSegmentSum","int32");(0,r.cQ)((0,r.dk)(n),(()=>"numSegments must be of dtype int"));const o={x:a,segmentIds:s},i={numSegments:n};return r.db.runKernel(r.cA,o,i)}}),Ln=(0,r.w)({unstack_:function(e,t=0){const n=(0,r.d9)(e,"x","unstack","string_or_numeric");(0,r.cQ)(t>=-n.shape.length&&t<n.shape.length,(()=>`Axis = ${t} is not in [-${n.shape.length}, ${n.shape.length})`));const a={value:n},s={axis:t};return r.db.runKernel(r.cz,a,s)}});function jn(e,t=!0,n,a){return r.db.makeVariable(e,t,n,a)}const Un=async function(e){const t=(0,r.d9)(e,"condition","whereAsync","bool"),n=await t.data(),a=(0,r.dw)(t.shape,n);return e!==t&&t.dispose(),a},Yn=async function(e,t,n){const a=(0,r.d9)(e,"tensor","boolMask"),s=(0,r.d9)(t,"mask","boolMask","bool"),o=null==n?0:n,i=s.rank,u=a.shape;(0,r.cQ)(i>0,(()=>"mask cannot be scalar")),(0,r.dp)(u.slice(o,o+i),s.shape,"mask's shape must match the first K dimensions of tensor's shape,");let c=1;for(let e=o;e<o+i;e++)c*=u[e];const l=u.slice(0,o).concat([c],u.slice(o+i)),d=(0,r.k)(a,l),h=(0,r.k)(s,[-1]),p=await Un(h),m=Dn(p,[1]),f=We(d,m,o);return e!==a&&a.dispose(),t!==s&&s.dispose(),m.dispose(),d.dispose(),h.dispose(),p.dispose(),f};function Jn(e,t,n=null){if(0===e.rank)return A(e);if(1!==e.rank&&null===n)return Jn((0,r.k)(e,[-1]),t,n);if(1===e.rank||"number"==typeof n||Array.isArray(n)&&1===n.length){if(1===t)return(0,r.t)(A(e),n);if(t===1/0)return it(A(e),n);if(t===-1/0)return yt(A(e),n);if("euclidean"===t||2===t)return Tn((0,r.t)(Gt(A(e),(0,r.n)(2,"int32")),n));throw new Error(`Error in norm: invalid ord value: ${t}`)}if(Array.isArray(n)&&2===n.length){if(1===t)return it((0,r.t)(A(e),n[0]),n[1]-1);if(t===1/0)return it((0,r.t)(A(e),n[1]),n[0]);if(t===-1/0)return yt((0,r.t)(A(e),n[1]),n[0]);if("fro"===t||"euclidean"===t)return Tn((0,r.t)(Nt(e),n));throw new Error(`Error in norm: invalid ord value: ${t}`)}throw new Error(`Error in norm: invalid axis: ${n}`)}const Zn=(0,r.w)({norm_:function(e,t="euclidean",n=null,a=!1){const s=Jn(e=(0,r.d9)(e,"x","norm"),t,n);let o=s.shape;if(a){const t=(0,r.dq)(n,e.shape);o=(0,r.dr)(s.shape,t)}return(0,r.k)(s,o)}}),Xn=(0,r.w)({movingAverage_:function(e,t,n,a,s=!0){const o=(0,r.d9)(e,"v","movingAverage"),i=(0,r.d9)(t,"x","movingAverage"),u=(0,r.d9)(n,"decay","movingAverage");(0,r.dx)(o,i),(0,r.cQ)((0,r.cR)(o.shape,i.shape),(()=>"Shape mismatch in v and x"));const c=(0,r.n)(1),l=ut(c,u);let d=(0,r.m)(ut(i,o),l);if(s){(0,r.cQ)(null!=a,(()=>"When using zeroDebias: true, step is required."));const e=(0,r.d9)(a,"step","movingAverage");d=I(d,ut(c,Gt(u,e)))}return M(o,d)}}),er=(0,r.w)({scatterND_:function(e,t,n){const a=(0,r.d9)(e,"indices","scatterND","int32"),s=(0,r.d9)(t,"updates","scatterND");(0,r.dy)(s,a,n);const o={indices:a,updates:s},i={shape:n};return r.db.runKernel(r.c2,o,i)}}),tr=(0,r.w)({sparseToDense_:function(e,t,n,a=0){const s=(0,r.d9)(e,"sparseIndices","sparseToDense","int32"),o=(0,r.d9)(t,"sparseValues","sparseToDense"),i=(0,r.d9)(a,"defaultValue","sparseToDense",o.dtype);!function(e,t,n,r){if("int32"!==e.dtype)throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${e.dtype}.`);if(e.rank>2)throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${e.shape}.`);const a=e.rank>0?e.shape[0]:1,s=e.rank>1?e.shape[1]:1;if(n.length!==s)throw new Error(`outputShape has incorrect number of elements:, ${n.length}, should be: ${s}.`);const o=t.size;if(0!==t.rank&&(1!==t.rank||o!==a))throw new Error(`sparseValues has incorrect shape ${t.shape}, should be [] or [${a}]`);if(t.dtype!==r.dtype)throw new Error("sparseValues.dtype must match defaultValues.dtype")}(s,o,n,i);const u={sparseIndices:s,sparseValues:o,defaultValue:i},c={outputShape:n};return r.db.runKernel(r.ck,u,c)}}),nr=(0,r.w)({gatherND_:function(e,t){const n=(0,r.d9)(t,"indices","gatherND","int32"),a={params:(0,r.d9)(e,"x","gatherND","string_or_numeric"),indices:n};return r.db.runKernel(r.b5,a)}}),rr=(0,r.w)({dropout_:function(e,t,n,a){const s=(0,r.d9)(e,"x","dropout");if((0,r.cQ)("float32"===s.dtype,(()=>`x has to be a floating point tensor since it's going to be scaled, but got a ${s.dtype} tensor instead.`)),(0,r.cQ)(t>=0&&t<1,(()=>`rate must be a float in the range [0, 1), but got ${t}.`)),0===t)return e instanceof r.T?s.clone():s;const o=function(e,t){if(null==t)return e.shape.slice();if((0,r.cR)(e.shape,t))return t;if(e.shape.length===t.length){const n=[];for(let r=0;r<e.shape.length;r++)null==t[r]&&null!=e.shape[r]?n.push(e.shape[r]):n.push(t[r]);return n}return t}(s,n),i=1-t,u=I(Re(M(an(o,0,1,"float32",a),i)),i);return(0,r.m)(s,u)}});function ar(e){return Math.floor(Math.pow(2,Math.ceil(Math.log(e)/Math.log(2))))}function sr(e,t,n){const r=1-e%2,a=new Float32Array(e);for(let s=0;s<e;++s){const o=2*Math.PI*s/(e+r-1);a[s]=t-n*Math.cos(o)}return Wn(a,"float32")}const or=async function(e,t,n=1){const a=(0,r.d9)(e,"predictions","inTopK"),s=(0,r.d9)(t,"targets","inTopK");(0,r.cQ)(a.rank>1,(()=>`inTopK() expects the predictions to be of rank 2 or higher, but got ${a.rank}`)),(0,r.cQ)(a.rank-1===s.rank,(()=>`predictions rank should be 1 larger than targets rank, but got predictions rank ${a.rank} and targets rank ${s.rank}`)),(0,r.dp)(a.shape.slice(0,a.shape.length-1),s.shape,"predictions's shape should be align with the targets' shape, except the last dimension.");const o=a.shape[a.shape.length-1];(0,r.cQ)(n>0&&n<=o,(()=>`'k' passed to inTopK() must be > 0 && <= the predictions last dimension (${o}), but got ${n}`));const i=await a.data(),u=await s.data(),[c,l]=[i.length/o,o],d=(0,r.dz)("bool",c);for(let e=0;e<c;e++){const t=e*l,r=i.subarray(t,t+l),a=[];for(let e=0;e<r.length;e++)a.push({value:r[e],index:e});a.sort(((e,t)=>t.value-e.value)),d[e]=0;for(let t=0;t<n;t++)if(a[t].index===u[e]){d[e]=1;break}}return e!==a&&a.dispose(),t!==s&&s.dispose(),(0,r.v)(d,s.shape,"bool")},ir=(0,r.w)({conv2DBackpropFilter_:function(e,t,n,a,s,o="NHWC",i){let u=e;3===e.rank&&(u=(0,r.k)(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let c=t;3===c.rank&&(c=(0,r.k)(t,[1,t.shape[0],t.shape[1],t.shape[2]])),(0,r.cQ)(4===u.rank,(()=>`Error in conv2dDerFilter: input must be rank 4, but got shape ${u.shape}.`)),(0,r.cQ)(4===c.rank,(()=>`Error in conv2dDerFilter: dy must be rank 4, but got shape ${c.shape}.`)),(0,r.cQ)(4===n.length,(()=>`Error in conv2dDerFilter: filterShape must be length 4, but got ${n}.`));const l="NHWC"===o?u.shape[3]:u.shape[1],d="NHWC"===o?c.shape[3]:c.shape[1];(0,r.cQ)(l===n[2],(()=>`Error in conv2dDerFilter: depth of input ${l}) must match input depth in filter (${n[2]}.`)),(0,r.cQ)(d===n[3],(()=>`Error in conv2dDerFilter: depth of dy (${d}) must match output depth for filter (${n[3]}).`)),null!=i&&(0,r.cQ)((0,r.dk)(s),(()=>`Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode ${i} but got pad ${s}.`));const h={x:u,dy:c},p={strides:a,pad:s,dataFormat:o,dimRoundingMode:i,filterShape:n};return r.db.runKernel(r.az,h,p)}}),ur=(0,r.w)({fusedConv2d_:function({x:e,filter:t,strides:n,pad:a,dataFormat:s="NHWC",dilations:o=[1,1],dimRoundingMode:i,bias:u,activation:c="linear",preluActivationWeights:l,leakyreluAlpha:d}){if(c=c||"linear",!1===(0,r.dA)(r.db.state.gradientDepth,c)){let h=ce(e,t,n,a,s,o,i);return null!=u&&(h=M(h,u)),(0,r.dB)(h,c,l,d)}const h=(0,r.d9)(e,"x","conv2d"),p=(0,r.d9)(t,"filter","conv2d");let m=h,f=!1;3===h.rank&&(f=!0,m=(0,r.k)(h,[1,h.shape[0],h.shape[1],h.shape[2]])),(0,r.cQ)(4===m.rank,(()=>`Error in fused conv2d: input must be rank 4, but got rank ${m.rank}.`)),(0,r.cQ)(4===p.rank,(()=>`Error in fused conv2d: filter must be rank 4, but got rank ${p.rank}.`)),null!=i&&(0,r.cQ)((0,r.dk)(a),(()=>`Error in fused conv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`)),(0,r.cQ)(m.shape[3]===p.shape[2],(()=>`Error in conv2d: depth of input (${m.shape[3]}) must match input depth for filter ${p.shape[2]}.`)),(0,r.cQ)((0,r.dj)(n,o),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${o}'`)),(0,r.cQ)("NHWC"===s,(()=>`Error in conv2d: got dataFormat of ${s} but only NHWC is currently supported.`));const b=(0,r.dC)(m.shape,p.shape,n,o,a,i);let g,w;null!=u&&(g=(0,r.d9)(u,"bias","fused conv2d"),[g]=(0,r.da)(g,h),(0,r.dm)(b.outShape,g.shape)),null!=l&&(w=(0,r.d9)(l,"prelu weights","fused conv2d"));const k=(e,t)=>{const[s,i,u,l]=t,d=(0,r.dD)(e,u,c);(0,r.cQ)((0,r.dE)(o),(()=>`Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${o}'`));const h=[de(i.shape,d,s,n,a),ir(i,d,s.shape,n,a)];if(null!=l){const e=(0,r.dF)(l,d);h.push(e)}return h},x={x:m,filter:p,bias:g,preluActivationWeights:w},v={strides:n,pad:a,dataFormat:s,dilations:o,dimRoundingMode:i,activation:c,leakyreluAlpha:d};return null==u?nt(((e,t,n)=>{let a=r.db.runKernel(r.cG,x,v);return n([t,e,a]),f&&(a=(0,r.k)(a,[a.shape[1],a.shape[2],a.shape[3]])),{value:a,gradFunc:k}}))(m,p):nt(((e,t,n,a)=>{let s=r.db.runKernel(r.cG,x,v);return a([t,e,s,n]),f&&(s=(0,r.k)(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:k}}))(m,p,g)}}),cr=(0,r.w)({depthwiseConv2dNativeBackpropFilter_:function(e,t,n,a,s,o=[1,1],i){let u=e;3===e.rank&&(u=(0,r.k)(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let c=t;3===c.rank&&(c=(0,r.k)(t,[1,t.shape[0],t.shape[1],t.shape[2]]));const l={x:u,dy:c},d={strides:a,pad:s,dimRoundingMode:i,dilations:o,filterShape:n};return r.db.runKernel(r.aL,l,d)}}),lr=(0,r.w)({depthwiseConv2dNativeBackpropInput_:function(e,t,n,a,s,o=[1,1],i){let u=t,c=!1;3===t.rank&&(c=!0,u=(0,r.k)(t,[1,t.shape[0],t.shape[1],t.shape[2]]));const l={dy:u,filter:n},d={strides:a,pad:s,dimRoundingMode:i,dilations:o,inputShape:e},h=r.db.runKernel(r.aM,l,d);return c?(0,r.k)(h,[h.shape[1],h.shape[2],h.shape[3]]):h}}),dr=(0,r.w)({fusedDepthwiseConv2d_:function({x:e,filter:t,strides:n,pad:a,dataFormat:s="NHWC",dilations:o=[1,1],dimRoundingMode:i,bias:u,activation:c="linear",preluActivationWeights:l,leakyreluAlpha:d}){if(!1===(0,r.dA)(r.db.state.gradientDepth,c)){let h=ve(e,t,n,a,s,o,i);return null!=u&&(h=M(h,u)),(0,r.dB)(h,c,l,d)}const h=(0,r.d9)(e,"x","depthwiseConv2d"),p=(0,r.d9)(t,"filter","depthwiseConv2d");let m=h,f=!1;3===h.rank&&(f=!0,m=(0,r.k)(h,[1,h.shape[0],h.shape[1],h.shape[2]])),(0,r.cQ)(4===m.rank,(()=>`Error in fused depthwiseConv2d: input must be rank 4, but got rank ${m.rank}.`)),(0,r.cQ)(4===p.rank,(()=>`Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${p.rank}.`)),(0,r.cQ)(m.shape[3]===p.shape[2],(()=>`Error in fused depthwiseConv2d: number of input channels (${m.shape[3]}) must match the inChannels dimension in filter ${p.shape[2]}.`)),null==o&&(o=[1,1]),(0,r.cQ)((0,r.dj)(n,o),(()=>`Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${n} and dilations '${o}'`)),null!=i&&(0,r.cQ)((0,r.dk)(a),(()=>`Error in fused depthwiseConv2d: pad must be an integer when using dimRoundingMode ${i} but got pad ${a}.`));const b=(0,r.dC)(m.shape,p.shape,n,o,a,i,!0);let g,w;null!=u&&(g=(0,r.d9)(u,"bias","fused conv2d"),[g]=(0,r.da)(g,h),(0,r.dm)(b.outShape,g.shape)),null!=l&&(w=(0,r.d9)(l,"prelu weights","fused depthwiseConv2d"));const k=(e,t)=>{(0,r.cQ)((0,r.dE)(o),(()=>`Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${o}'`));const[s,u,l,d]=t,h=(0,r.dD)(e,l,c),p=lr(u.shape,h,s,n,a,o,i),m=cr(u,h,s.shape,n,a,o,i);return null!=d?[p,m,(0,r.dF)(g,h)]:[p,m]},x={x:m,filter:p,bias:g,preluActivationWeights:w},v={strides:n,pad:a,dataFormat:s,dilations:o,dimRoundingMode:i,activation:c,leakyreluAlpha:d};return null==u?nt(((e,t,n)=>{let a=r.db.runKernel(r.cH,x,v);return n([t,e,a]),f&&(a=(0,r.k)(a,[a.shape[1],a.shape[2],a.shape[3]])),{value:a,gradFunc:k}}))(m,p):nt(((e,t,n,a)=>{let s=r.db.runKernel(r.cH,x,v);return a([t,e,s,n]),f&&(s=(0,r.k)(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:k}}))(m,p,g)}}),hr=(0,r.w)({fusedMatMul_:function({a:e,b:t,transposeA:n=!1,transposeB:a=!1,bias:s,activation:o="linear",preluActivationWeights:i,leakyreluAlpha:c}){if(!1===(0,r.dA)(r.db.state.gradientDepth,o)){let l=u(e,t,n,a);return null!=s&&(l=M(l,s)),(0,r.dB)(l,o,i,c)}let l=(0,r.d9)(e,"a","fused matMul"),d=(0,r.d9)(t,"b","fused matMul");[l,d]=(0,r.da)(l,d);const h=n?l.shape[l.rank-2]:l.shape[l.rank-1],p=a?d.shape[d.rank-1]:d.shape[d.rank-2],m=n?l.shape[l.rank-1]:l.shape[l.rank-2],f=a?d.shape[d.rank-2]:d.shape[d.rank-1],b=l.shape.slice(0,-2),g=d.shape.slice(0,-2),w=(0,r.dt)(b),k=(0,r.dt)(g);(0,r.cQ)(l.rank>=2&&d.rank>=2&&l.rank===d.rank,(()=>`Error in fused matMul: inputs must have the same rank of at least 2, got ranks ${l.rank} and ${d.rank}.`)),(0,r.cQ)((0,r.cR)(b,g),(()=>`Error in fused matMul: outer dimensions (${b}) and (${g}) of Tensors with shapes ${l.shape} and ${d.shape} must match.`)),(0,r.cQ)(h===p,(()=>`Error in fused matMul: inner shapes (${h}) and (${p}) of Tensors with shapes ${l.shape} and ${d.shape} and transposeA=${n} and transposeB=${a} must match.`));const x=l.shape.slice(0,-2).concat([m,f]),v=n?(0,r.k)(l,[w,h,m]):(0,r.k)(l,[w,m,h]),y=a?(0,r.k)(d,[k,f,p]):(0,r.k)(d,[k,p,f]);let E,$;null!=s&&(E=(0,r.d9)(s,"bias","fused matMul"),[E]=(0,r.da)(E,l),(0,r.dm)(x,E.shape)),null!=i&&($=(0,r.d9)(i,"prelu weights","fused matMul"));const _=(e,t)=>{const[i,c,l,d]=t,h=(0,r.dD)((0,r.k)(e,l.shape),l,o);let p,m;return n||a?!n&&a?(p=u(h,c,!1,!1),m=u(h,i,!0,!1)):n&&!a?(p=u(c,h,!1,!0),m=u(i,h,!1,!1)):(p=u(c,h,!0,!0),m=u(h,i,!0,!0)):(p=u(h,c,!1,!0),m=u(i,h,!0,!1)),null!=s?[p,m,(0,r.dF)(d,h)]:[p,m]},N={a:v,b:y,bias:E,preluActivationWeights:$},S={transposeA:n,transposeB:a,activation:o,leakyreluAlpha:c};return null==s?nt(((e,t,n)=>{const a=r.db.runKernel(r.cF,N,S);return n([e,t,a]),{value:(0,r.k)(a,x),gradFunc:_}}))(v,y):nt(((e,t,n,a)=>{const s=r.db.runKernel(r.cF,N,S);return a([e,t,s,n]),{value:(0,r.k)(s,x),gradFunc:_}}))(v,y,E)}});var pr=Object.freeze({__proto__:null,conv2d:ur,depthwiseConv2d:dr,matMul:hr});const mr=(0,r.w)({hammingWindow_:function(e){return sr(e,.54,.46)}}),fr=(0,r.w)({hannWindow_:function(e){return sr(e,.5,.5)}}),br=(0,r.w)({frame_:function(e,t,n,a=!1,s=0){let o=0;const i=[];for(;o+t<=e.size;)i.push(L(e,o,t)),o+=n;if(a)for(;o<e.size;){const r=o+t-e.size,a=H([L(e,o,t-r),ze([r],s)]);i.push(a),o+=n}return 0===i.length?qn([],[0,t]):(0,r.k)(H(i),[i.length,t])}}),gr=(0,r.w)({stft_:function(e,t,n,a,s=fr){null==a&&(a=ar(t));const o=br(e,t,n),i=(0,r.m)(o,s(t));return An(i,a)}}),wr=(0,r.w)({cropAndResize_:function(e,t,n,a,s="bilinear",o=0){const i=(0,r.d9)(e,"image","cropAndResize"),u=(0,r.d9)(t,"boxes","cropAndResize","float32"),c=(0,r.d9)(n,"boxInd","cropAndResize","int32"),l=u.shape[0];(0,r.cQ)(4===i.rank,(()=>`Error in cropAndResize: image must be rank 4,but got rank ${i.rank}.`)),(0,r.cQ)(2===u.rank&&4===u.shape[1],(()=>`Error in cropAndResize: boxes must be have size [${l},4] but had shape ${u.shape}.`)),(0,r.cQ)(1===c.rank&&c.shape[0]===l,(()=>`Error in cropAndResize: boxInd must be have size [${l}] but had shape ${u.shape}.`)),(0,r.cQ)(2===a.length,(()=>`Error in cropAndResize: cropSize must be of length 2, but got length ${a.length}.`)),(0,r.cQ)(a[0]>=1&&a[1]>=1,(()=>`cropSize must be atleast [1,1], but was ${a}`)),(0,r.cQ)("bilinear"===s||"nearest"===s,(()=>`method must be bilinear or nearest, but was ${s}`));const d={image:i,boxes:u,boxInd:c},h={method:s,extrapolationValue:o,cropSize:a};return r.db.runKernel(r.aH,d,h)}}),kr=(0,r.w)({flipLeftRight_:function(e){const t=(0,r.d9)(e,"image","flipLeftRight","float32");(0,r.cQ)(4===t.rank,(()=>`Error in flipLeftRight: image must be rank 4,but got rank ${t.rank}.`));const n={image:t};return r.db.runKernel(r.b0,n,{})}}),xr=(0,r.w)({rotateWithOffset_:function(e,t,n=0,a=.5){const s=(0,r.d9)(e,"image","rotateWithOffset","float32");(0,r.cQ)(4===s.rank,(()=>`Error in rotateWithOffset: image must be rank 4,but got rank ${s.rank}.`));const o={image:s},i={radians:t,fillValue:n,center:a};return r.db.runKernel(r.cE,o,i)}});function vr(e,t,n,a,s,o){null==a&&(a=.5),null==s&&(s=Number.NEGATIVE_INFINITY),null==o&&(o=0);const i=e.shape[0];return n=Math.min(n,i),(0,r.cQ)(0<=a&&a<=1,(()=>`iouThreshold must be in [0, 1], but was '${a}'`)),(0,r.cQ)(2===e.rank,(()=>`boxes must be a 2D tensor, but was of rank '${e.rank}'`)),(0,r.cQ)(4===e.shape[1],(()=>`boxes must have 4 columns, but 2nd dimension was ${e.shape[1]}`)),(0,r.cQ)(1===t.rank,(()=>"scores must be a 1D tensor")),(0,r.cQ)(t.shape[0]===i,(()=>`scores has incompatible shape with boxes. Expected ${i}, but was ${t.shape[0]}`)),(0,r.cQ)(0<=o&&o<=1,(()=>`softNmsSigma must be in [0, 1], but was '${o}'`)),{maxOutputSize:n,iouThreshold:a,scoreThreshold:s,softNmsSigma:o}}const yr=(0,r.w)({nonMaxSuppression_:function(e,t,n,a=.5,s=Number.NEGATIVE_INFINITY){const o=(0,r.d9)(e,"boxes","nonMaxSuppression"),i=(0,r.d9)(t,"scores","nonMaxSuppression"),u=vr(o,i,n,a,s),c={maxOutputSize:n=u.maxOutputSize,iouThreshold:a=u.iouThreshold,scoreThreshold:s=u.scoreThreshold};return r.db.runKernel(r.bG,{boxes:o,scores:i},c)}}),Er=(0,r.w)({nonMaxSuppressionWithScore_:function(e,t,n,a=.5,s=Number.NEGATIVE_INFINITY,o=0){const i=(0,r.d9)(e,"boxes","nonMaxSuppression"),u=(0,r.d9)(t,"scores","nonMaxSuppression"),c=vr(i,u,n,a,s,o),l={boxes:i,scores:u},d={maxOutputSize:n=c.maxOutputSize,iouThreshold:a=c.iouThreshold,scoreThreshold:s=c.scoreThreshold,softNmsSigma:o=c.softNmsSigma},h=r.db.runKernel(r.bI,l,d);return{selectedIndices:h[0],selectedScores:h[1]}}}),$r=(0,r.w)({nonMaxSuppressionPadded_:function(e,t,n,a=.5,s=Number.NEGATIVE_INFINITY,o=!1){const i=(0,r.d9)(e,"boxes","nonMaxSuppression"),u=(0,r.d9)(t,"scores","nonMaxSuppression"),c=vr(i,u,n,a,s,null),l={boxes:i,scores:u},d={maxOutputSize:c.maxOutputSize,iouThreshold:c.iouThreshold,scoreThreshold:c.scoreThreshold,padToMaxOutputSize:o},h=r.db.runKernel(r.bH,l,d);return{selectedIndices:h[0],validOutputs:h[1]}}}),_r=(0,r.w)({resizeBilinear_:function(e,t,n=!1,a=!1){const s=(0,r.d9)(e,"images","resizeBilinear");(0,r.cQ)(3===s.rank||4===s.rank,(()=>`Error in resizeBilinear: x must be rank 3 or 4, but got rank ${s.rank}.`)),(0,r.cQ)(2===t.length,(()=>`Error in resizeBilinear: new shape must 2D, but got shape ${t}.`)),(0,r.cQ)(!1===a||!1===n,(()=>"Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false."));let o=s,i=!1;3===s.rank&&(i=!0,o=(0,r.k)(s,[1,s.shape[0],s.shape[1],s.shape[2]]));const u={images:o},c={alignCorners:n,halfPixelCenters:a,size:t},l=r.db.runKernel(r.bY,u,c);return i?(0,r.k)(l,[l.shape[1],l.shape[2],l.shape[3]]):l}}),Nr=(0,r.w)({resizeNearestNeighbor_:function(e,t,n=!1,a=!1){const s=(0,r.d9)(e,"images","resizeNearestNeighbor");(0,r.cQ)(3===s.rank||4===s.rank,(()=>`Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${s.rank}.`)),(0,r.cQ)(2===t.length,(()=>`Error in resizeNearestNeighbor: new shape must 2D, but got shape ${t}.`)),(0,r.cQ)("float32"===s.dtype||"int32"===s.dtype,(()=>"`images` must have `int32` or `float32` as dtype")),(0,r.cQ)(!1===a||!1===n,(()=>"Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false."));let o=s,i=!1;3===s.rank&&(i=!0,o=(0,r.k)(s,[1,s.shape[0],s.shape[1],s.shape[2]]));const u={images:o},c={alignCorners:n,halfPixelCenters:a,size:t},l=r.db.runKernel(r.bW,u,c);return i?(0,r.k)(l,[l.shape[1],l.shape[2],l.shape[3]]):l}}),Sr=(0,r.w)({threshold_:function(e,t="binary",n=!1,a=.5){const s=(0,r.d9)(e,"image","threshold"),o=s.shape[0]*s.shape[1];let i,u,c,l,d=(0,r.m)(Wn([a]),255);if((0,r.cQ)(3===s.rank,(()=>`Error in threshold: image must be rank 3,but got rank ${s.rank}.`)),(0,r.cQ)(3===s.shape[2]||1===s.shape[2],(()=>`Error in threshold: image color channel must be equal to 3 or 1but got ${s.shape[2]}.`)),(0,r.cQ)("int32"===s.dtype||"float32"===s.dtype,(()=>`Error in dtype: image dtype must be int32 or float32,but got dtype ${s.dtype}.`)),(0,r.cQ)("otsu"===t||"binary"===t,(()=>`Method must be binary or otsu, but was ${t}`)),3===s.shape[2]){[i,u,c]=In(s,[1,1,1],-1);const e=(0,r.m)(i,.2989),t=(0,r.m)(u,.587),n=(0,r.m)(c,.114);l=M(M(e,t),n)}else l=e;"otsu"===t&&(d=function(e,t){let n,a,s,o,i,u,c=Wn([-1]),l=Wn([0]),d=Wn([0]);for(let h=0;h<e.size-1;h++){n=L(e,0,h+1),a=L(e,h+1),i=I((0,r.t)(n),t),u=I((0,r.t)(a),t);const p=(0,r.t)((0,r.m)(n,sn(0,n.size)));s=I(p,(0,r.t)(n));const m=ze(a.shape,n.size),f=M(sn(0,a.size),m),b=(0,r.m)(a,f);o=I((0,r.t)(b),(0,r.t)(a));const g=ut(s,o),w=ut(s,o),k=(0,r.m)(i,u);d=(0,r.m)((0,r.m)(k,g),w);const x=qe(d,l);l=_e(x,d,l),c=_e(x,Wn([h]),c)}return c}(te((0,r.d)(mn(l),"int32"),(0,r.v)([]),256),o));const h=n?He(l,d):qe(l,d);return(0,r.d)((0,r.m)(h,255),"int32")}}),Mr=(0,r.w)({transform_:function(e,t,n="nearest",a="constant",s=0,o){const i=(0,r.d9)(e,"image","transform","float32"),u=(0,r.d9)(t,"transforms","transform","float32");(0,r.cQ)(4===i.rank,(()=>`Error in transform: image must be rank 4,but got rank ${i.rank}.`)),(0,r.cQ)(2===u.rank&&(u.shape[0]===i.shape[0]||1===u.shape[0])&&8===u.shape[1],(()=>"Error in transform: Input transform should be batch x 8 or 1 x 8")),(0,r.cQ)(null==o||2===o.length,(()=>`Error in transform: outputShape must be [height, width] or null, but got ${o}.`));const c={image:i,transforms:u},l={interpolation:n,fillMode:a,fillValue:s,outputShape:o};return r.db.runKernel(r.cw,c,l)}}),Qr=(0,r.w)({bandPart_:function(e,t,n){(0,r.cQ)(t%1==0,(()=>`bandPart(): numLower must be an integer, got ${t}.`)),(0,r.cQ)(n%1==0,(()=>`bandPart(): numUpper must be an integer, got ${n}.`));const a=(0,r.d9)(e,"a","bandPart");(0,r.cQ)(a.rank>=2,(()=>`bandPart(): Rank must be at least 2, got ${a.rank}.`));const s=a.shape,[o,i]=a.shape.slice(-2);if(!(t<=o))throw new Error(`bandPart(): numLower (${t}) must not be greater than the number of rows (${o}).`);if(!(n<=i))throw new Error(`bandPart(): numUpper (${n}) must not be greater than the number of columns (${i}).`);t<0&&(t=o),n<0&&(n=i);const u=(0,r.k)(sn(0,o,1,"int32"),[-1,1]),c=sn(0,i,1,"int32"),l=ut(u,c),d=dt(He(l,(0,r.n)(+t,"int32")),Ge(l,(0,r.n)(-n,"int32"))),h=(0,r.z)([o,i],a.dtype);return(0,r.k)(Kn(Ln((0,r.k)(a,[-1,o,i])).map((e=>_e(d,e,h)))),s)}}),Ir=(0,r.w)({gramSchmidt_:function(e){let t;if(Array.isArray(e)){t=!1,(0,r.cQ)(null!=e&&e.length>0,(()=>"Gram-Schmidt process: input must not be null, undefined, or empty"));const n=e[0].shape[0];for(let t=1;t<e.length;++t)(0,r.cQ)(e[t].shape[0]===n,(()=>`Gram-Schmidt: Non-unique lengths found in the input vectors: (${e[t].shape[0]} vs. ${n})`))}else t=!0,e=In(e,e.shape[0],0).map((e=>Dn(e,[0])));(0,r.cQ)(e.length<=e[0].shape[0],(()=>`Gram-Schmidt: Number of vectors (${e.length}) exceeds number of dimensions (${e[0].shape[0]}).`));const n=[],a=e;for(let t=0;t<e.length;++t)n.push(r.db.tidy((()=>{let e=a[t];if(t>0)for(let a=0;a<t;++a){const t=(0,r.m)((0,r.t)((0,r.m)(n[a],e)),n[a]);e=ut(e,t)}return I(e,Zn(e,"euclidean"))})));return t?Kn(n,0):n}});function Ar(e,t=!1){return r.db.tidy((()=>{(0,r.cQ)(2===e.shape.length,(()=>`qr2d() requires a 2D Tensor, but got a ${e.shape.length}D Tensor.`));const n=e.shape[0],a=e.shape[1];let s=Ke(n),o=(0,r.f)(e);const i=qn([[1]],[1,1]);let c=(0,r.f)(i);const d=n>=a?a:n;for(let e=0;e<d;++e){const t=o,d=c,h=s;[c,o,s]=r.db.tidy((()=>{const t=L(o,[e,e],[n-e,1]),d=Zn(t),h=L(o,[e,e],[1,1]),p=_e(qe(h,0),qn([[-1]]),qn([[1]])),m=ut(h,(0,r.m)(p,d)),f=I(t,m);c=1===f.shape[0]?(0,r.f)(i):H([i,L(f,[1,0],[f.shape[0]-1,f.shape[1]])],0);const b=at(I(u(p,m),d)),g=L(o,[e,0],[n-e,a]),w=(0,r.m)(b,c),k=l(c);if(0===e)o=ut(g,u(w,u(k,g)));else{const t=ut(g,u(w,u(k,g)));o=H([L(o,[0,0],[e,a]),t],0)}const x=l(w),v=L(s,[0,e],[n,s.shape[1]-e]);if(0===e)s=ut(v,u(u(v,c),x));else{const t=ut(v,u(u(v,c),x));s=H([L(s,[0,0],[n,e]),t],1)}return[c,o,s]})),(0,r.J)([t,d,h])}return!t&&n>a&&(s=L(s,[0,0],[n,a]),o=L(o,[0,0],[a,a])),[s,o]}))}const Tr=(0,r.w)({qr_:function(e,t=!1){if((0,r.cQ)(e.rank>=2,(()=>`qr() requires input tensor to have a rank >= 2, but got rank ${e.rank}`)),2===e.rank)return Ar(e,t);{const n=e.shape.slice(0,e.shape.length-2).reduce(((e,t)=>e*t)),a=Ln((0,r.k)(e,[n,e.shape[e.shape.length-2],e.shape[e.shape.length-1]]),0),s=[],o=[];return a.forEach((e=>{const[n,r]=Ar(e,t);s.push(n),o.push(r)})),[(0,r.k)(Kn(s,0),e.shape),(0,r.k)(Kn(o,0),e.shape)]}}});var Cr;!function(e){e[e.NONE=0]="NONE",e[e.MEAN=1]="MEAN",e[e.SUM=2]="SUM",e[e.SUM_BY_NONZERO_WEIGHTS=3]="SUM_BY_NONZERO_WEIGHTS"}(Cr||(Cr={}));const Dr=(0,r.w)({computeWeightedLoss_:function(e,t,n=Cr.SUM_BY_NONZERO_WEIGHTS){const a=(0,r.d9)(e,"losses","computeWeightedLoss");let s=null;null!=t&&(s=(0,r.d9)(t,"weights","computeWeightedLoss"));const o=null==s?a:(0,r.m)(a,s);if(n===Cr.NONE)return o;if(n===Cr.SUM)return(0,r.t)(o);if(n===Cr.MEAN){if(null==s)return kt(o);{const e=a.size/s.size,t=I((0,r.t)(o),(0,r.t)(s));return e>1?I(t,(0,r.n)(e)):t}}if(n===Cr.SUM_BY_NONZERO_WEIGHTS){if(null==s)return I((0,r.t)(o),(0,r.n)(a.size));{const e=(0,r.m)(s,xt(a.shape)),t=(0,r.d)((0,r.t)(It(e,(0,r.n)(0))),"float32");return I((0,r.t)(o),t)}}throw Error(`Unknown reduction: ${n}`)}}),Kr=(0,r.w)({absoluteDifference_:function(e,t,n,a=Cr.SUM_BY_NONZERO_WEIGHTS){const s=(0,r.d9)(e,"labels","absoluteDifference"),o=(0,r.d9)(t,"predictions","absoluteDifference");let i=null;null!=n&&(i=(0,r.d9)(n,"weights","absoluteDifference")),(0,r.dp)(s.shape,o.shape,"Error in absoluteDifference: ");const u=A(ut(s,o));return Dr(u,i,a)}}),zr=(0,r.w)({cosineDistance_:function(e,t,n,a,s=Cr.SUM_BY_NONZERO_WEIGHTS){const o=(0,r.d9)(e,"labels","cosineDistance"),i=(0,r.d9)(t,"predictions","cosineDistance");let u=null;null!=a&&(u=(0,r.d9)(a,"weights","cosineDistance")),(0,r.dp)(o.shape,i.shape,"Error in cosineDistance: ");const c=(0,r.n)(1),l=ut(c,(0,r.t)((0,r.m)(o,i),n,!0));return Dr(l,u,s)}}),Rr=(0,r.w)({hingeLoss_:function(e,t,n,a=Cr.SUM_BY_NONZERO_WEIGHTS){let s=(0,r.d9)(e,"labels","hingeLoss");const o=(0,r.d9)(t,"predictions","hingeLoss");let i=null;null!=n&&(i=(0,r.d9)(n,"weights","hingeLoss")),(0,r.dp)(s.shape,o.shape,"Error in hingeLoss: ");const u=(0,r.n)(1);s=ut((0,r.m)((0,r.n)(2),s),u);const c=(0,r.r)(ut(u,(0,r.m)(s,o)));return Dr(c,i,a)}}),Wr=(0,r.w)({huberLoss_:function(e,t,n,a=1,s=Cr.SUM_BY_NONZERO_WEIGHTS){const o=(0,r.d9)(e,"labels","huberLoss"),i=(0,r.d9)(t,"predictions","huberLoss");let u=null;null!=n&&(u=(0,r.d9)(n,"weights","huberLoss")),(0,r.dp)(o.shape,i.shape,"Error in huberLoss: ");const c=(0,r.n)(a),l=A(ut(i,o)),d=Et(l,c),h=ut(l,d),p=M((0,r.m)((0,r.n)(.5),Nt(d)),(0,r.m)(c,h));return Dr(p,u,s)}}),qr=(0,r.w)({logLoss_:function(e,t,n,a=1e-7,s=Cr.SUM_BY_NONZERO_WEIGHTS){const o=(0,r.d9)(e,"labels","logLoss"),i=(0,r.d9)(t,"predictions","logLoss");let u=null;null!=n&&(u=(0,r.d9)(n,"weights","logLoss")),(0,r.dp)(o.shape,i.shape,"Error in logLoss: ");const c=(0,r.n)(1),l=(0,r.n)(a),d=at((0,r.m)(o,Ue(M(i,l)))),h=(0,r.m)(ut(c,o),Ue(M(ut(c,i),l))),p=ut(d,h);return Dr(p,u,s)}}),Gr=(0,r.w)({meanSquaredError_:function(e,t,n,a=Cr.SUM_BY_NONZERO_WEIGHTS){const s=(0,r.d9)(e,"labels","meanSquaredError"),o=(0,r.d9)(t,"predictions","meanSquaredError");let i=null;null!=n&&(i=(0,r.d9)(n,"weights","meanSquaredError")),(0,r.dp)(s.shape,o.shape,"Error in meanSquaredError: ");const u=Cn(s,o);return Dr(u,i,a)}}),Fr=(0,r.w)({sigmoidCrossEntropy_:function(e,t,n,a=0,s=Cr.SUM_BY_NONZERO_WEIGHTS){let o=(0,r.d9)(e,"multiClassLabels","sigmoidCrossEntropy");const i=(0,r.d9)(t,"logits","sigmoidCrossEntropy");let u=null;if(null!=n&&(u=(0,r.d9)(n,"weights","sigmoidCrossEntropy")),(0,r.dp)(o.shape,i.shape,"Error in sigmoidCrossEntropy: "),a>0){const e=(0,r.n)(a),t=(0,r.n)(1),n=(0,r.n)(.5);o=M((0,r.m)(o,ut(t,e)),(0,r.m)(n,e))}const c=function(e,t){const n=(0,r.d9)(e,"labels","sigmoidCrossEntropyWithLogits"),a=(0,r.d9)(t,"logits","sigmoidCrossEntropyWithLogits");(0,r.dp)(n.shape,a.shape,"Error in sigmoidCrossEntropyWithLogits: ");const s=(0,r.r)(a),o=(0,r.m)(a,n),i=Ye(Ae(at(A(a))));return M(ut(s,o),i)}(o,i);return Dr(c,u,s)}}),Pr=(0,r.w)({softmaxCrossEntropy_:function(e,t,n,a=0,s=Cr.SUM_BY_NONZERO_WEIGHTS){let o=(0,r.d9)(e,"onehotLabels","softmaxCrossEntropy");const i=(0,r.d9)(t,"logits","softmaxCrossEntropy");let u=null;if(null!=n&&(u=(0,r.d9)(n,"weights","softmaxCrossEntropy")),(0,r.dp)(o.shape,i.shape,"Error in softmaxCrossEntropy: "),a>0){const e=(0,r.n)(a),t=(0,r.n)(1),n=(0,r.n)(o.shape[1]);o=M((0,r.m)(o,ut(t,e)),I(e,n))}const c=function(e,t,n=-1){if(-1===n&&(n=t.rank-1),n!==t.rank-1)throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${t.rank} and dim was ${n}`);return nt(((e,t,a)=>{const s=lt(t,[n],!0),o=ut((0,r.d)(t,"float32"),s);a([e,o]);const i=at((0,r.m)(o,e));return{value:(0,r.t)(i,[n]),gradFunc:(e,t)=>{const[a,s]=t,o=(0,r.dr)(e.shape,[n]);return[(0,r.m)((0,r.k)(e,o),ut((0,r.d)(a,"float32"),Ae(s))),(0,r.m)((0,r.k)(e,o),ut(Ae(s),(0,r.d)(a,"float32")))]}}}))(e,t)}(o,i);return Dr(c,u,s)}}),Br=(0,r.w)({sparseFillEmptyRows_:function(e,t,n,a){const s=(0,r.d9)(e,"indices","sparseFillEmptyRows"),o=(0,r.d9)(t,"values","sparseFillEmptyRows"),i=(0,r.d9)(n,"denseShape","sparseFillEmptyRows"),u=(0,r.d9)(a,"defaultValue","sparseFillEmptyRows",o.dtype);if(2!==s.rank)throw new Error(`Indices should be Tensor2D but received shape\n        ${s.shape}`);if(1!==o.rank)throw new Error(`Values should be Tensor1D but received shape ${o.shape}`);if(1!==i.rank)throw new Error(`Dense shape should be Tensor1D but received shape ${i.shape}`);if(0!==u.rank)throw new Error(`Default value should be a scalar but received shape ${u.shape}`);const c={indices:s,values:o,denseShape:i,defaultValue:u},l=r.db.runKernel(r.cg,c);return{outputIndices:l[0],outputValues:l[1],emptyRowIndicator:l[2],reverseIndexMap:l[3]}}}),Or=(0,r.w)({sparseReshape_:function(e,t,n){const a=(0,r.d9)(e,"inputIndices","sparseReshape"),s=(0,r.d9)(t,"inputShape","sparseReshape"),o=(0,r.d9)(n,"newShape","sparseReshape");if(2!==a.rank)throw new Error(`Input indices should be Tensor2D but received shape\n        ${a.shape}`);if(1!==s.rank)throw new Error(`Input shape should be Tensor1D but received shape ${s.shape}`);if(1!==o.rank)throw new Error(`New shape should be Tensor1D but received shape ${o.shape}`);const i={inputIndices:a,inputShape:s,newShape:o},u=r.db.runKernel(r.ch,i);return{outputIndices:u[0],outputShape:u[1]}}}),Vr=(0,r.w)({sparseSegmentMean_:function(e,t,n){const a=(0,r.d9)(e,"data","sparseSegmentMean"),s=(0,r.d9)(t,"indices","sparseSegmentMean"),o=(0,r.d9)(n,"segmentIds","sparseSegmentMean");if(a.rank<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==s.rank)throw new Error(`Indices should be Tensor1D but received shape\n          ${s.shape}`);if(1!==o.rank)throw new Error(`Segment ids should be Tensor1D but received shape\n          ${o.shape}`);const i={data:a,indices:s,segmentIds:o};return r.db.runKernel(r.ci,i)}}),Hr=(0,r.w)({sparseSegmentSum_:function(e,t,n){const a=(0,r.d9)(e,"data","sparseSegmentSum"),s=(0,r.d9)(t,"indices","sparseSegmentSum"),o=(0,r.d9)(n,"segmentIds","sparseSegmentSum");if(a.rank<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==s.rank)throw new Error(`Indices should be Tensor1D but received shape\n         ${s.shape}`);if(1!==o.rank)throw new Error(`Segment ids should be Tensor1D but received shape\n         ${o.shape}`);const i={data:a,indices:s,segmentIds:o};return r.db.runKernel(r.cj,i)}}),Lr=(0,r.w)({stringNGrams_:function(e,t,n,a,s,o,i,u){const c=(0,r.d9)(e,"data","stringNGrams","string");if("string"!==c.dtype)throw new Error("Data must be of datatype string");if(1!==c.shape.length)throw new Error(`Data must be a vector, saw: ${c.shape}`);const l=(0,r.d9)(t,"dataSplits","stringNGrams");if("int32"!==l.dtype)throw new Error("Data splits must be of datatype int32");const d={separator:n,nGramWidths:a,leftPad:s,rightPad:o,padWidth:i,preserveShortSequences:u},h={data:c,dataSplits:l},p=r.db.runKernel(r.co,h,d);return{nGrams:p[0],nGramsSplits:p[1]}}}),jr=(0,r.w)({stringSplit_:function(e,t,n=!0){const a=(0,r.d9)(e,"input","stringSplit","string"),s=(0,r.d9)(t,"delimiter","stringSplit","string");if(1!==a.rank)throw new Error(`Input should be Tensor1D but received shape ${a.shape}`);if(0!==s.rank)throw new Error(`Delimiter should be a scalar but received shape ${s.shape}`);const o={skipEmpty:n},i={input:a,delimiter:s},u=r.db.runKernel(r.cp,i,o);return{indices:u[0],values:u[1],shape:u[2]}}}),Ur=(0,r.w)({stringToHashBucketFast_:function(e,t){const n=(0,r.d9)(e,"input","stringToHashBucketFast","string"),a={numBuckets:t};if(t<=0)throw new Error("Number of buckets must be at least 1");const s={input:n};return r.db.runKernel(r.cq,s,a)}}),Yr={fft:Sn,ifft:Mn,rfft:An,irfft:Qn},Jr={hammingWindow:mr,hannWindow:fr,frame:br,stft:gr},Zr={flipLeftRight:kr,resizeNearestNeighbor:Nr,resizeBilinear:_r,rotateWithOffset:xr,cropAndResize:wr,nonMaxSuppression:yr,nonMaxSuppressionAsync:async function(e,t,n,a=.5,s=Number.NEGATIVE_INFINITY){const o=(0,r.d9)(e,"boxes","nonMaxSuppressionAsync"),i=(0,r.d9)(t,"scores","nonMaxSuppressionAsync"),u=vr(o,i,n,a,s);n=u.maxOutputSize,a=u.iouThreshold,s=u.scoreThreshold;const c=await Promise.all([o.data(),i.data()]),l=c[0],d=c[1],{selectedIndices:h}=(0,r.dG)(l,d,n,a,s);return o!==e&&o.dispose(),i!==t&&i.dispose(),Wn(h,"int32")},nonMaxSuppressionWithScore:Er,nonMaxSuppressionWithScoreAsync:async function(e,t,n,a=.5,s=Number.NEGATIVE_INFINITY,o=0){const i=(0,r.d9)(e,"boxes","nonMaxSuppressionAsync"),u=(0,r.d9)(t,"scores","nonMaxSuppressionAsync"),c=vr(i,u,n,a,s,o);n=c.maxOutputSize,a=c.iouThreshold,s=c.scoreThreshold,o=c.softNmsSigma;const l=await Promise.all([i.data(),u.data()]),d=l[0],h=l[1],{selectedIndices:p,selectedScores:m}=(0,r.dH)(d,h,n,a,s,o);return i!==e&&i.dispose(),u!==t&&u.dispose(),{selectedIndices:Wn(p,"int32"),selectedScores:Wn(m)}},nonMaxSuppressionPadded:$r,nonMaxSuppressionPaddedAsync:async function(e,t,n,a=.5,s=Number.NEGATIVE_INFINITY,o=!1){const i=(0,r.d9)(e,"boxes","nonMaxSuppressionAsync"),u=(0,r.d9)(t,"scores","nonMaxSuppressionAsync"),c=vr(i,u,n,a,s,null),l=c.maxOutputSize,d=c.iouThreshold,h=c.scoreThreshold,[p,m]=await Promise.all([i.data(),u.data()]),{selectedIndices:f,validOutputs:b}=(0,r.dI)(p,m,l,d,h,o);return i!==e&&i.dispose(),u!==t&&u.dispose(),{selectedIndices:Wn(f,"int32"),validOutputs:(0,r.n)(b,"int32")}},threshold:Sr,transform:Mr},Xr={bandPart:Qr,gramSchmidt:Ir,qr:Tr},ea={absoluteDifference:Kr,computeWeightedLoss:Dr,cosineDistance:zr,hingeLoss:Rr,huberLoss:Wr,logLoss:qr,meanSquaredError:Gr,sigmoidCrossEntropy:Fr,softmaxCrossEntropy:Pr},ta={sparseFillEmptyRows:Br,sparseReshape:Or,sparseSegmentMean:Vr,sparseSegmentSum:Hr},na={stringNGrams:Lr,stringSplit:jr,stringToHashBucketFast:Ur};class ra extends k{minimize(e,t=!1,n){const{value:a,grads:s}=this.computeGradients(e,n);if(null!=n){const e=n.map((e=>({name:e.name,tensor:s[e.name]})));this.applyGradients(e)}else this.applyGradients(s);return(0,r.J)(s),t?a:(a.dispose(),null)}get iterations(){return null==this.iterations_&&(this.iterations_=0),this.iterations_}incrementIterations(){this.iterations_=this.iterations+1}computeGradients(e,t){return tt(e,t)}dispose(){null!=this.iterations_&&(0,r.J)(this.iterations_)}async saveIterations(){return null==this.iterations_&&(this.iterations_=0),{name:"iter",tensor:(0,r.n)(this.iterations_,"int32")}}async getWeights(){throw new Error("getWeights() is not implemented for this optimizer yet.")}async setWeights(e){throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`)}async extractIterations(e){return this.iterations_=(await e[0].tensor.data())[0],e.slice(1)}}Object.defineProperty(ra,Symbol.hasInstance,{value:e=>null!=e.minimize&&null!=e.computeGradients&&null!=e.applyGradients});class aa extends ra{constructor(e,t,n=null){super(),this.learningRate=e,this.rho=t,this.epsilon=n,this.accumulatedGrads=[],this.accumulatedUpdates=[],null==n&&(this.epsilon=r.db.backend.epsilon())}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const a=r.db.registeredVariables[t];null==this.accumulatedGrads[n]&&(this.accumulatedGrads[n]={originalName:`${t}/accum_grad`,variable:(0,r.I)((()=>Ne(a).variable(!1)))}),null==this.accumulatedUpdates[n]&&(this.accumulatedUpdates[n]={originalName:`${t}/accum_var`,variable:(0,r.I)((()=>Ne(a).variable(!1)))});const s=Array.isArray(e)?e[n].tensor:e[t];if(null==s)return;const o=this.accumulatedGrads[n].variable,i=this.accumulatedUpdates[n].variable;(0,r.I)((()=>{const e=M((0,r.m)(o,this.rho),(0,r.m)(Nt(s),1-this.rho)),t=(0,r.m)(I(Tn(M(i,this.epsilon)),Tn(M(o,this.epsilon))),s),n=M((0,r.m)(i,this.rho),(0,r.m)(Nt(t),1-this.rho));o.assign(e),i.assign(n);const u=M((0,r.m)(t,-this.learningRate),a);a.assign(u)}))})),this.incrementIterations()}dispose(){null!=this.accumulatedUpdates&&((0,r.J)(this.accumulatedGrads.map((e=>e.variable))),(0,r.J)(this.accumulatedUpdates.map((e=>e.variable))))}async getWeights(){const e=[...this.accumulatedGrads,...this.accumulatedUpdates];return[await this.saveIterations()].concat(e.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){const t=(e=await this.extractIterations(e)).length/2;this.accumulatedGrads=e.slice(0,t).map((e=>({originalName:e.name,variable:e.tensor.variable(!1)}))),this.accumulatedUpdates=e.slice(t,2*t).map((e=>({originalName:e.name,variable:e.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,rho:this.rho,epsilon:this.epsilon}}static fromConfig(e,t){return new e(t.learningRate,t.rho,t.epsilon)}}aa.className="Adadelta",v(aa);class sa extends ra{constructor(e,t=.1){super(),this.learningRate=e,this.initialAccumulatorValue=t,this.accumulatedGrads=[]}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const a=r.db.registeredVariables[t];if(null==this.accumulatedGrads[n]){const e=!1;this.accumulatedGrads[n]={originalName:`${t}/accumulator`,variable:(0,r.I)((()=>ze(a.shape,this.initialAccumulatorValue).variable(e)))}}const s=Array.isArray(e)?e[n].tensor:e[t];if(null==s)return;const o=this.accumulatedGrads[n].variable;(0,r.I)((()=>{const e=M(o,Nt(s));o.assign(e);const t=M((0,r.m)(I(s,Tn(M(e,r.db.backend.epsilon()))),-this.learningRate),a);a.assign(t)}))})),this.incrementIterations()}dispose(){null!=this.accumulatedGrads&&(0,r.J)(this.accumulatedGrads.map((e=>e.variable)))}async getWeights(){return[await this.saveIterations()].concat(this.accumulatedGrads.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e),this.accumulatedGrads=e.map((e=>({originalName:e.name,variable:e.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,initialAccumulatorValue:this.initialAccumulatorValue}}static fromConfig(e,t){return new e(t.learningRate,t.initialAccumulatorValue)}}sa.className="Adagrad",v(sa);class oa extends ra{constructor(e,t,n,a=null){super(),this.learningRate=e,this.beta1=t,this.beta2=n,this.epsilon=a,this.accumulatedFirstMoment=[],this.accumulatedSecondMoment=[],(0,r.I)((()=>{this.accBeta1=(0,r.n)(t).variable(),this.accBeta2=(0,r.n)(n).variable()})),null==a&&(this.epsilon=r.db.backend.epsilon())}applyGradients(e){const t=Array.isArray(e)?e.map((e=>e.name)):Object.keys(e);(0,r.I)((()=>{const n=ut(1,this.accBeta1),a=ut(1,this.accBeta2);t.forEach(((t,s)=>{const o=r.db.registeredVariables[t];null==this.accumulatedFirstMoment[s]&&(this.accumulatedFirstMoment[s]={originalName:`${t}/m`,variable:(0,r.I)((()=>Ne(o).variable(!1)))}),null==this.accumulatedSecondMoment[s]&&(this.accumulatedSecondMoment[s]={originalName:`${t}/v`,variable:(0,r.I)((()=>Ne(o).variable(!1)))});const i=Array.isArray(e)?e[s].tensor:e[t];if(null==i)return;const u=this.accumulatedFirstMoment[s].variable,c=this.accumulatedSecondMoment[s].variable,l=M((0,r.m)(u,this.beta1),(0,r.m)(i,1-this.beta1)),d=M((0,r.m)(c,this.beta2),(0,r.m)(Nt(i),1-this.beta2)),h=I(l,n),p=I(d,a);u.assign(l),c.assign(d);const m=M((0,r.m)(I(h,M(Tn(p),this.epsilon)),-this.learningRate),o);o.assign(m)})),this.accBeta1.assign((0,r.m)(this.accBeta1,this.beta1)),this.accBeta2.assign((0,r.m)(this.accBeta2,this.beta2))})),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.accBeta2.dispose(),null!=this.accumulatedFirstMoment&&(0,r.J)(this.accumulatedFirstMoment.map((e=>e.variable))),null!=this.accumulatedSecondMoment&&(0,r.J)(this.accumulatedSecondMoment.map((e=>e.variable)))}async getWeights(){const e=[...this.accumulatedFirstMoment,...this.accumulatedSecondMoment];return[await this.saveIterations()].concat(e.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e),(0,r.I)((()=>{this.accBeta1.assign(Gt(this.beta1,this.iterations_+1)),this.accBeta2.assign(Gt(this.beta2,this.iterations_+1))}));const t=e.length/2;this.accumulatedFirstMoment=e.slice(0,t).map((e=>({originalName:e.name,variable:e.tensor.variable(!1)}))),this.accumulatedSecondMoment=e.slice(t,2*t).map((e=>({originalName:e.name,variable:e.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon}}static fromConfig(e,t){return new e(t.learningRate,t.beta1,t.beta2,t.epsilon)}}oa.className="Adam",v(oa);class ia extends ra{constructor(e,t,n,a=null,s=0){super(),this.learningRate=e,this.beta1=t,this.beta2=n,this.epsilon=a,this.decay=s,this.accumulatedFirstMoment=[],this.accumulatedWeightedInfNorm=[],(0,r.I)((()=>{this.iteration=(0,r.n)(0).variable(),this.accBeta1=(0,r.n)(t).variable()})),null==a&&(this.epsilon=r.db.backend.epsilon())}applyGradients(e){const t=Array.isArray(e)?e.map((e=>e.name)):Object.keys(e);(0,r.I)((()=>{const n=ut(1,this.accBeta1),a=I(-this.learningRate,M((0,r.m)(this.iteration,this.decay),1));t.forEach(((t,s)=>{const o=r.db.registeredVariables[t];null==this.accumulatedFirstMoment[s]&&(this.accumulatedFirstMoment[s]={originalName:`${t}/m`,variable:Ne(o).variable(!1)}),null==this.accumulatedWeightedInfNorm[s]&&(this.accumulatedWeightedInfNorm[s]={originalName:`${t}/v`,variable:Ne(o).variable(!1)});const i=Array.isArray(e)?e[s].tensor:e[t];if(null==i)return;const u=this.accumulatedFirstMoment[s].variable,c=this.accumulatedWeightedInfNorm[s].variable,l=M((0,r.m)(u,this.beta1),(0,r.m)(i,1-this.beta1)),d=(0,r.m)(c,this.beta2),h=A(i),p=wt(d,h);u.assign(l),c.assign(p);const m=M((0,r.m)(I(a,n),I(l,M(p,this.epsilon))),o);o.assign(m)})),this.iteration.assign(M(this.iteration,1)),this.accBeta1.assign((0,r.m)(this.accBeta1,this.beta1))})),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.iteration.dispose(),null!=this.accumulatedFirstMoment&&(0,r.J)(this.accumulatedFirstMoment.map((e=>e.variable))),null!=this.accumulatedWeightedInfNorm&&(0,r.J)(this.accumulatedWeightedInfNorm.map((e=>e.variable)))}async getWeights(){throw new Error("getWeights() is not implemented for Adamax yet.")}async setWeights(e){throw new Error("setWeights() is not implemented for Adamax yet.")}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon,decay:this.decay}}static fromConfig(e,t){return new e(t.learningRate,t.beta1,t.beta2,t.epsilon,t.decay)}}ia.className="Adamax",v(ia);class ua extends ra{constructor(e){super(),this.learningRate=e,this.setLearningRate(e)}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const a=Array.isArray(e)?e[n].tensor:e[t];if(null==a)return;const s=r.db.registeredVariables[t];(0,r.I)((()=>{const e=M((0,r.m)(this.c,a),s);s.assign(e)}))})),this.incrementIterations()}setLearningRate(e){this.learningRate=e,null!=this.c&&this.c.dispose(),this.c=(0,r.L)((0,r.n)(-e))}dispose(){this.c.dispose()}async getWeights(){return[await this.saveIterations()]}async setWeights(e){if(0!==(e=await this.extractIterations(e)).length)throw new Error("SGD optimizer does not have settable weights.")}getConfig(){return{learningRate:this.learningRate}}static fromConfig(e,t){return new e(t.learningRate)}}ua.className="SGD",v(ua);class ca extends ua{constructor(e,t,n=!1){super(e),this.learningRate=e,this.momentum=t,this.useNesterov=n,this.accumulations=[],this.m=(0,r.n)(this.momentum)}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const a=r.db.registeredVariables[t];if(null==this.accumulations[n]){const e=!1;this.accumulations[n]={originalName:`${t}/momentum`,variable:(0,r.I)((()=>Ne(a).variable(e)))}}const s=this.accumulations[n].variable,o=Array.isArray(e)?e[n].tensor:e[t];null!=o&&(0,r.I)((()=>{let e;const t=M((0,r.m)(this.m,s),o);e=this.useNesterov?M((0,r.m)(this.c,M(o,(0,r.m)(t,this.m))),a):M((0,r.m)(this.c,t),a),s.assign(t),a.assign(e)}))})),this.incrementIterations()}dispose(){this.m.dispose(),null!=this.accumulations&&(0,r.J)(this.accumulations.map((e=>e.variable)))}setMomentum(e){this.momentum=e}async getWeights(){return[await this.saveIterations()].concat(this.accumulations.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e),this.accumulations=e.map((e=>({originalName:e.name,variable:e.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,momentum:this.momentum,useNesterov:this.useNesterov}}static fromConfig(e,t){return new e(t.learningRate,t.momentum,t.useNesterov)}}ca.className="Momentum",v(ca);class la extends ra{constructor(e,t=.9,n=0,a=null,s=!1){if(super(),this.learningRate=e,this.decay=t,this.momentum=n,this.epsilon=a,this.accumulatedMeanSquares=[],this.accumulatedMoments=[],this.accumulatedMeanGrads=[],this.centered=s,null==a&&(this.epsilon=r.db.backend.epsilon()),null==e)throw new Error("learningRate for RMSPropOptimizer must be defined.")}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const a=r.db.registeredVariables[t],s=!1;null==this.accumulatedMeanSquares[n]&&(this.accumulatedMeanSquares[n]={originalName:`${t}/rms`,variable:(0,r.I)((()=>Ne(a).variable(s)))}),null==this.accumulatedMoments[n]&&(this.accumulatedMoments[n]={originalName:`${t}/momentum`,variable:(0,r.I)((()=>Ne(a).variable(s)))}),null==this.accumulatedMeanGrads[n]&&this.centered&&(this.accumulatedMeanGrads[n]={originalName:`${t}/mg`,variable:(0,r.I)((()=>Ne(a).variable(s)))});const o=Array.isArray(e)?e[n].tensor:e[t];if(null==o)return;const i=this.accumulatedMeanSquares[n].variable,u=this.accumulatedMoments[n].variable;(0,r.I)((()=>{const e=M((0,r.m)(i,this.decay),(0,r.m)(Nt(o),1-this.decay));if(this.centered){const t=this.accumulatedMeanGrads[n].variable,s=M((0,r.m)(t,this.decay),(0,r.m)(o,1-this.decay)),c=I((0,r.m)(o,this.learningRate),Tn(ut(e,M(Nt(s),this.epsilon)))),l=M((0,r.m)(u,this.momentum),c);i.assign(e),t.assign(s),u.assign(l);const d=ut(a,l);a.assign(d)}else{const e=M((0,r.m)(i,this.decay),(0,r.m)(Nt(o),1-this.decay)),t=M((0,r.m)(u,this.momentum),I((0,r.m)(o,this.learningRate),Tn(M(e,this.epsilon))));i.assign(e),u.assign(t);const n=ut(a,t);a.assign(n)}}))})),this.incrementIterations()}dispose(){null!=this.accumulatedMeanSquares&&(0,r.J)(this.accumulatedMeanSquares.map((e=>e.variable))),null!=this.accumulatedMeanGrads&&this.centered&&(0,r.J)(this.accumulatedMeanGrads.map((e=>e.variable))),null!=this.accumulatedMoments&&(0,r.J)(this.accumulatedMoments.map((e=>e.variable)))}async getWeights(){const e=[...this.accumulatedMeanSquares,...this.accumulatedMoments];return this.centered&&e.push(...this.accumulatedMeanGrads),[await this.saveIterations()].concat(e.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e);const t=this.centered?e.length/3:e.length/2,n=!1;this.accumulatedMeanSquares=e.slice(0,t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)}))),this.accumulatedMoments=e.slice(t,2*t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)}))),this.centered&&(this.accumulatedMeanGrads=e.slice(2*t,3*t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)}))))}getConfig(){return{learningRate:this.learningRate,decay:this.decay,momentum:this.momentum,epsilon:this.epsilon,centered:this.centered}}static fromConfig(e,t){return new e(t.learningRate,t.decay,t.momentum,t.epsilon,t.centered)}}la.className="RMSProp",v(la);class da{static sgd(e){return new ua(e)}static momentum(e,t,n=!1){return new ca(e,t,n)}static rmsprop(e,t=.9,n=0,r=null,a=!1){return new la(e,t,n,r,a)}static adam(e=.001,t=.9,n=.999,r=null){return new oa(e,t,n,r)}static adadelta(e=.001,t=.95,n=null){return new aa(e,t,n)}static adamax(e=.002,t=.9,n=.999,r=null,a=0){return new ia(e,t,n,r,a)}static adagrad(e,t=.1){return new sa(e,t)}}const ha={sgd:da.sgd,momentum:da.momentum,adadelta:da.adadelta,adagrad:da.adagrad,rmsprop:da.rmsprop,adamax:da.adamax,adam:da.adam},pa="undefined"!=typeof requestAnimationFrame?requestAnimationFrame:"undefined"!=typeof setImmediate?setImmediate:e=>e();function ma(){return new Promise((e=>pa((()=>e()))))}var fa=Object.freeze({__proto__:null,nonMaxSuppressionV3Impl:r.dG,nonMaxSuppressionV4Impl:r.dI,nonMaxSuppressionV5Impl:r.dH,whereImpl:r.dw})}}]);